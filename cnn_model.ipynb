{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2fa8334",
   "metadata": {},
   "source": [
    "### 모듈 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5640e314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings             \n",
    "warnings.filterwarnings(action='ignore')          # 경고 문구 무시\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"   # 셀 하나에 ouput 모두 출력 가능\n",
    "import numpy as np                            \n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "#  한글글꼴로 변경\n",
    "plt.rcParams['font.size'] = 12.0\n",
    "# plt.rcParams['font.family'] = 'batang'\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'  \n",
    "plt.rc('axes', unicode_minus = False)\n",
    "\n",
    "# plot 크기\n",
    "plt.rc('figure', figsize=(10,6))\n",
    "\n",
    "# 음수 표시 에러 \n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "import json\n",
    "pd.options.display.max_rows= 10    # 화면에 최대 12개까지 결과 출력\n",
    "np.random.seed(0)\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43e80435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "from keras.applications import vgg16\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6d03d3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x20b1ca0cb20>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.models.load_model('model/best-cnn-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4dd71626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "408358ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def set_env():\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    config = tf.compat.v1.ConfigProto(log_device_placement=True)\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.75\n",
    "    session = tf.compat.v1.Session(config=config)\n",
    "    session\n",
    "set_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bc84d2",
   "metadata": {},
   "source": [
    "### ImgaeDataenertator\n",
    "컨볼루션 신경망 모델을 위한 데이터 부풀리기 클래스\n",
    "+ 학습 도중에 이미지에 임의 변형 및 정규화 적용\n",
    "+ 변형된 이미지를 배치 단위로 불러올 수 있는 generator 생성.\n",
    "    + generator를 생성할 때 flow(data, labels), flow_from_directory(directory) 두 가지 함수를 사용합니다.\n",
    "    + fit_generator, evaluate_generator 함수를 이용하여 generator로 이미지를 불러와서 모델을 학습시킬 수 있습니\n",
    "\n",
    "#### 파라미터(기본값)\n",
    "<code style=\"display:block\">\n",
    "+keras.preprocessing.image.ImageDataGenerator(\n",
    "featurewise_center=False,\n",
    "samplewise_center=False,\n",
    "featurewise_std_normalization=False,\n",
    "samplewise_std_normalization=False,\n",
    "zca_whitening=False,\n",
    "rotation_range=0.,\n",
    "width_shift_range=0.,\n",
    "height_shift_range=0.,\n",
    "shear_range=0.,\n",
    "zoom_range=0.,\n",
    "channel_shift_range=0.,\n",
    "fill_mode='nearest',\n",
    "cval=0.,\n",
    "horizontal_flip=False,\n",
    "vertical_flip=False,\n",
    "rescale=None,\n",
    "preprocessing_function=None,\n",
    "data_format=K.image_data_format())\n",
    "</code>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff200522",
   "metadata": {},
   "source": [
    "+ shear_range : 범위 내에서 임의로 원본 이미지 변형(0.5면 0~0.5각도로 )\n",
    "+ zoom_range : 지정된 범위내로 임의로 원본이미지 확대/축소 0.3 이면 -0.3~0.3 범위 로 확대축소\n",
    "+ rotation_range : 지정된 각도 범위내로 임의로 원본 이미지 회전(90이면 0~90 다함)\n",
    "+ width_shift_range : 지정된 수평방향 이동 범위로 원본 이미지 이동 : 0.1이면 넓이 100에서 0~10px 좌우 이동\n",
    "+ height_shift_range :수직방향\n",
    "+ vertical_flip : 수직방향 뒤집기 (boolean)\n",
    "+ horizontal_flip 수평방향 뒤집기 True일경우 50% 확률로 이미지를 수평으로 뒤집\n",
    "+ fill_mode 이미지를 회전, 이동하거나 축소할 때 생기는 공간을 채우는 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae1497a",
   "metadata": {},
   "source": [
    "데이터 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e286207",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.getcwd() + '\\\\datas\\\\train'\n",
    "test_path = os.getcwd() + '\\\\datas\\\\test'\n",
    "valid_path = os.getcwd() + '\\\\datas\\\\val'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c461b1a",
   "metadata": {},
   "source": [
    "### 이미지 유효성 검사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c78960c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "label_counts = {}\n",
    "idx = ['train', 'test', 'valid']\n",
    "def get_train_data(): \n",
    "    data_input = []\n",
    "    error_paths = []\n",
    "    for i, path in enumerate([train_path, test_path, valid_path]):\n",
    "        label_dirs = os.listdir(path)\n",
    "        for dir_name in label_dirs:\n",
    "            file_list = os.listdir(f'{path}\\\\{dir_name}')\n",
    "            label_counts[f'{idx[i]}_{dir_name}'] = len(file_list)\n",
    "            for file_name in file_list:\n",
    "                try:\n",
    "#                     print(file_name)\n",
    "                    img = Image.open(f'{path}\\\\{dir_name}\\\\{file_name}')\n",
    "                    im = img.load()\n",
    "\n",
    "                except Exception as e:\n",
    "                        err_string = f'[Error!] at {path}\\\\{dir_name}\\\\{file_name}'\n",
    "                        error_paths.append(err_string)\n",
    "                        print(err_string)\n",
    "                        print(e)\n",
    "                        continue\n",
    "\n",
    "\n",
    "get_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25eb56fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_cockroach': 4356,\n",
       " 'train_etc': 3425,\n",
       " 'train_spider': 7908,\n",
       " 'test_cockroach': 1074,\n",
       " 'test_etc': 3864,\n",
       " 'test_spider': 2006,\n",
       " 'valid_cockroach': 1064,\n",
       " 'valid_etc': 3924,\n",
       " 'valid_spider': 1966}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6ce5b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f4ac61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c51e276c",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8fd39b",
   "metadata": {},
   "source": [
    "검증 및 테스트 이미지는 augmentation을 적용하지 않습니다. 모델 성능을 평가할 때에는 이미지 원본을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cf65db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataGen = ImageDataGenerator(\n",
    "                       rescale=1/255,              # scale\n",
    "                       fill_mode='nearest',        # 변형시 공간 채우는방식\n",
    "                       rotation_range=40,         # 회전\n",
    "                       shear_range=.2,           # 전단 변환\n",
    "                       vertical_flip=True,      # 수직 뒤집기\n",
    "                       horizontal_flip=True,    # 수평 뒤집기\n",
    "                       height_shift_range=.2,    # 이미지 수직 이동\n",
    "                       width_shift_range=.2,    # 수평 이동\n",
    "                       zoom_range=.2,          # -0.2~0.2 확대 축소\n",
    ")\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d1c12c",
   "metadata": {},
   "source": [
    "#### 데이터 디버깅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fd05cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "                       fill_mode='nearest',        # 변형시 공간 채우는방식\n",
    "                       rotation_range=40,         # 회전\n",
    "                       shear_range=.2,           # 전단 변환\n",
    "                       vertical_flip=True,      # 수직 뒤집기\n",
    "                       horizontal_flip=True,    # 수평 뒤집기\n",
    "                       height_shift_range=.2,    # 이미지 수직 이동\n",
    "                       width_shift_range=.2,    # 수평 이동\n",
    "                       zoom_range=.2,          # -0.2~0.2 확대 축소\n",
    ")         \n",
    "\n",
    "img = load_img('C:/project/phobiaFilter/dataset/train/cockroach_many/cockr534.jpg')  # PIL 이미지\n",
    "img2 = load_img('C:/project/phobiaFilter/dataset/train/cockroach_many/cockroache-1569.jpg')  # PIL 이미지\n",
    "\n",
    "x = img_to_array(img)  # (3, 150, 150) 크기의 NumPy 배열\n",
    "x = x.reshape((1,) + x.shape)  \n",
    "x2 = img_to_array(img2)  # (3, 150, 150) 크기의 NumPy 배열\n",
    "x2 = x2.reshape((1,) + x2.shape)  \n",
    "\n",
    "# 아래 .flow() 함수는 임의 변환된 이미지를 배치 단위로 생성해서\n",
    "# 지정된 `preview/` 폴더에 저장합니다.\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir='C:\\project\\phobiaFilter\\dataset\\preview', save_prefix='cocks', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 40:\n",
    "        break  # 이미지 20장을 생성하고 마칩니다\n",
    "\n",
    "i=0\n",
    "for batch in datagen.flow(x2, batch_size=1,\n",
    "                  save_to_dir='C:\\project\\phobiaFilter\\dataset\\preview', save_prefix='cocks2', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 40:\n",
    "        break  # 이미지 20장을 생성하고 마칩니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91610254",
   "metadata": {},
   "source": [
    "#### Data 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d8902381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15689 images belonging to 3 classes.\n",
      "Found 6940 images belonging to 3 classes.\n",
      "Found 6946 images belonging to 3 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x2062534da90>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x20625328340>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x206253284f0>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "train_generator = train_dataGen.flow_from_directory(train_path, target_size=(150,150), batch_size=batch_size, class_mode='categorical')\n",
    "test_generator = valid_datagen.flow_from_directory(test_path, target_size=(150,150), batch_size=batch_size, class_mode='categorical')\n",
    "valid_generator = test_datagen.flow_from_directory(valid_path, target_size=(150,150), batch_size=batch_size, class_mode='categorical')\n",
    "train_generator\n",
    "test_generator\n",
    "valid_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "844116b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cockroach': 0, 'etc': 1, 'spider': 2}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices\n",
    "len(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fc6b40",
   "metadata": {},
   "source": [
    "엔트로피 용량을 조절하는 방법은 다양합니다. 대표적으로 모델에 관여하는 파라미터 개수를 조절하는 방법이 있습니다. 레이어 개수와 레이어 크기가 여기에 해당하죠. 저희가 작은 규모의 CNN을 사용하는 이유가 여기에 있습니다. 또한, L1, L2 정규화 (regularization) 같은 가중치 정규화 기법이 있습니다. 학습하면서 모든 가중치를 반복적으로 축소하는 방법인데, 결과적으로 핵심적인 특징에 대한 가중치만 남게 되는 효과가 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de9e028",
   "metadata": {},
   "source": [
    "### 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fecf35b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model = keras.Sequential()\n",
    "# # 필터 층 추가 \n",
    "# # same 패딩을 적용했기 때문에 특성맵과 입력의 크기가 동일\n",
    "# model.add(keras.layers.Conv2D(32, kernel_size=10, activation='relu',\n",
    "#                               padding='same', input_shape=(150,150,1)))\n",
    "\n",
    "# model.add(keras.layers.MaxPooling2D(2))\n",
    "# model.add(keras.layers.Conv2D(64, kernel_size=10, activation='relu', padding='same'))\n",
    "# model.add(keras.layers.MaxPooling2D(2))\n",
    "# model.add(keras.layers.Flatten())    # 출력층 입력을 위해 1차원 변환\n",
    "# model.add(keras.layers.Dense(200, activation='relu'))\n",
    "# model.add(keras.layers.Dropout(0.4))            # 과대적합 방지 \n",
    "# model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "# model.summary()\n",
    "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "# checkpoint_cb = keras.callbacks.ModelCheckpoint('model/best-cnn-model.h5')\n",
    "# early_stopping_cb = keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)\n",
    "# history = model.fit(train_scaled, train_target, epochs=20, validation_data=(valid_scaled, valid_target),\n",
    "#                     callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.xlabel('epoch')\n",
    "# plt.ylabel('loss')\n",
    "# plt.legend(['train', 'val'])\n",
    "# plt.show();\n",
    "\n",
    "\n",
    "# model.evaluate(valid_scaled, valid_target)\n",
    "# model.evaluate(test_scaled, test_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b3d41d",
   "metadata": {},
   "source": [
    "### 정확도와 손실율 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2eafdbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# acc = history.history['accuracy']\n",
    "# val_acc = history.history['val_accuracy']\n",
    "# loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "\n",
    "# epochs = range(len(acc))\n",
    "\n",
    "# plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "# plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "# plt.title('Training and validation accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.figure()\n",
    "\n",
    "# plt.plot(epochs, loss, 'go', label='Training Loss')\n",
    "# plt.plot(epochs, val_loss, 'g', label='Validation Loss')\n",
    "# plt.title('Training and validation loss')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd394528",
   "metadata": {},
   "source": [
    "### 첫 번째 모델\n",
    "+ 훈련셋 : 정확도 50%\n",
    "+ 검증셋 : 정확도 30% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "772464ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "981/981 [==============================] - 197s 198ms/step - loss: 1.0609 - accuracy: 0.4835 - val_loss: 1.2306 - val_accuracy: 0.2819\n",
      "Epoch 2/40\n",
      "981/981 [==============================] - 198s 201ms/step - loss: 1.0386 - accuracy: 0.4996 - val_loss: 1.2419 - val_accuracy: 0.2819\n",
      "Epoch 3/40\n",
      "981/981 [==============================] - 190s 194ms/step - loss: 1.0380 - accuracy: 0.5023 - val_loss: 1.2575 - val_accuracy: 0.2819\n",
      "Epoch 4/40\n",
      "981/981 [==============================] - 194s 197ms/step - loss: 1.0339 - accuracy: 0.5040 - val_loss: 1.2438 - val_accuracy: 0.2819\n",
      "Epoch 5/40\n",
      "981/981 [==============================] - 196s 199ms/step - loss: 1.0300 - accuracy: 0.5094 - val_loss: 1.2486 - val_accuracy: 0.2819\n",
      "Epoch 6/40\n",
      "981/981 [==============================] - 195s 199ms/step - loss: 1.0385 - accuracy: 0.4976 - val_loss: 1.2358 - val_accuracy: 0.2819\n",
      "Epoch 7/40\n",
      "981/981 [==============================] - 202s 206ms/step - loss: 1.0408 - accuracy: 0.4950 - val_loss: 1.2590 - val_accuracy: 0.2819\n",
      "Epoch 8/40\n",
      "981/981 [==============================] - 203s 207ms/step - loss: 1.0319 - accuracy: 0.5086 - val_loss: 1.2567 - val_accuracy: 0.2819\n",
      "Epoch 9/40\n",
      "981/981 [==============================] - 191s 194ms/step - loss: 1.0358 - accuracy: 0.5015 - val_loss: 1.2536 - val_accuracy: 0.2819\n",
      "Epoch 10/40\n",
      "981/981 [==============================] - 204s 208ms/step - loss: 1.0326 - accuracy: 0.5071 - val_loss: 1.2453 - val_accuracy: 0.2819\n",
      "Epoch 11/40\n",
      "981/981 [==============================] - 189s 192ms/step - loss: 1.0318 - accuracy: 0.5075 - val_loss: 1.2457 - val_accuracy: 0.2819\n",
      "Epoch 12/40\n",
      "981/981 [==============================] - ETA: 0s - loss: 1.0365 - accuracy: 0.4988"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-240d38bb2b5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m               metrics='accuracy')\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m model.fit_generator(\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1916\u001b[0m                   \u001b[1;34m'will be removed in a future version. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1917\u001b[0m                   'Please use `Model.fit`, which supports generators.')\n\u001b[1;32m-> 1918\u001b[1;33m     return self.fit(\n\u001b[0m\u001b[0;32m   1919\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1187\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1189\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1190\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1462\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1463\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1464\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1465\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1466\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    922\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(512, activation='relu', kernel_size=(3,3), padding='same', input_shape=(150,150,3)))\n",
    "model.add(MaxPooling2D(2))\n",
    "\n",
    "model.add(Conv2D(256, activation='relu', kernel_size=(3,3), padding='same', input_shape=(150,150,3)))\n",
    "model.add(MaxPooling2D(2))\n",
    "\n",
    "model.add(Conv2D(128, activation='relu', kernel_size=(3,3), padding='same', input_shape=(150,150,3)))\n",
    "model.add(MaxPooling2D(2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(len(train_generator.class_indices), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics='accuracy')\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        validation_data=valid_generator,\n",
    "#         validation_steps=50,\n",
    "    #verbose=2\n",
    "        epochs=40)\n",
    "model.save_weights('model/first_model.h5')  # 많은 시간을 들여 학습한 모델인 만큼, 학습 후에는 꼭 모델을 저장해줍시다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bbf4e3",
   "metadata": {},
   "source": [
    "### 두번째 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82ecd7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fff1220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = applications.vgg16.VGG16(include_top=False, weights='imagenet', input_shape=(150,150,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5e1ced8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15689 images belonging to 3 classes.\n",
      "Found 6940 images belonging to 3 classes.\n",
      "Found 6946 images belonging to 3 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x250894ce220>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x25088d3b3d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x25088d3b2b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "train_generator = train_dataGen.flow_from_directory(train_path, target_size=(150,150), batch_size=batch_size, class_mode=None, shuffle=False)\n",
    "test_generator = valid_datagen.flow_from_directory(test_path, target_size=(150,150), batch_size=batch_size, class_mode=None, shuffle=False)\n",
    "valid_generator = test_datagen.flow_from_directory(valid_path, target_size=(150,150), batch_size=batch_size, class_mode=None, shuffle=False)\n",
    "train_generator\n",
    "test_generator\n",
    "valid_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ae24a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_features_train = vgg_model.predict_generator(train_generator, train_generator.samples//batch_size)\n",
    "np.save(open('model/bottleneck_features_train2.npy', 'wb'), bottleneck_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef6555e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_features_valid = vgg_model.predict_generator(valid_generator, valid_generator.samples//batch_size)\n",
    "np.save(open('model/bottleneck_features_valid2.npy', 'wb'), bottleneck_features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79dd1e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[2.9638262 , 0.        , 0.        , ..., 0.        ,\n",
       "          0.5799281 , 0.        ],\n",
       "         [3.1682796 , 0.        , 0.        , ..., 0.        ,\n",
       "          0.56045103, 0.        ],\n",
       "         [1.3320899 , 0.        , 0.14621115, ..., 0.        ,\n",
       "          0.82582194, 0.        ],\n",
       "         [1.4184277 , 0.        , 0.2643201 , ..., 0.        ,\n",
       "          0.7630368 , 0.        ]],\n",
       "\n",
       "        [[2.7745922 , 0.        , 0.        , ..., 0.        ,\n",
       "          0.67750555, 0.        ],\n",
       "         [2.8662744 , 0.        , 0.26052243, ..., 0.        ,\n",
       "          0.33991322, 0.        ],\n",
       "         [1.3859388 , 0.        , 1.2953296 , ..., 0.        ,\n",
       "          0.8689036 , 0.        ],\n",
       "         [0.83747655, 0.        , 1.3656135 , ..., 0.        ,\n",
       "          0.98654073, 0.        ]],\n",
       "\n",
       "        [[0.82537097, 0.        , 0.15404952, ..., 0.        ,\n",
       "          0.7168837 , 0.        ],\n",
       "         [1.4893606 , 0.        , 0.27200404, ..., 0.        ,\n",
       "          0.37301528, 0.        ],\n",
       "         [1.1949186 , 0.        , 1.3631682 , ..., 0.        ,\n",
       "          0.21403497, 0.        ],\n",
       "         [0.8629099 , 0.        , 1.4689734 , ..., 0.        ,\n",
       "          0.2917834 , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.16445273, ..., 0.        ,\n",
       "          1.0053123 , 0.        ],\n",
       "         [1.1543388 , 0.        , 0.30699113, ..., 0.        ,\n",
       "          0.7293269 , 0.        ],\n",
       "         [1.0871084 , 0.        , 1.1732965 , ..., 0.        ,\n",
       "          0.24979383, 0.        ],\n",
       "         [1.3288467 , 0.        , 1.432009  , ..., 0.        ,\n",
       "          0.06714875, 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.38626865, 0.        , 0.        , ..., 0.        ,\n",
       "          0.90207386, 0.        ],\n",
       "         [0.30835155, 0.        , 0.        , ..., 0.        ,\n",
       "          0.6992088 , 0.        ],\n",
       "         [0.10277915, 0.        , 0.        , ..., 0.        ,\n",
       "          0.5402227 , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.52758646, 0.        ]],\n",
       "\n",
       "        [[0.09779538, 0.        , 0.        , ..., 0.        ,\n",
       "          0.85069853, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.78826326, 0.        ],\n",
       "         [0.        , 0.        , 0.11023241, ..., 0.        ,\n",
       "          0.5706941 , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.5136966 , 0.        ]],\n",
       "\n",
       "        [[0.08690858, 0.        , 0.        , ..., 0.        ,\n",
       "          0.6674414 , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.55962324, 0.        ],\n",
       "         [0.        , 0.        , 0.01718789, ..., 0.        ,\n",
       "          0.28051984, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.63066757, 0.        ]],\n",
       "\n",
       "        [[0.09375441, 0.        , 0.        , ..., 0.        ,\n",
       "          0.45861763, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.0055961 , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.08710527, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.27561674, 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          1.3478851 , 0.        ],\n",
       "         [0.12446725, 0.        , 0.        , ..., 0.        ,\n",
       "          1.6059191 , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.95320654, 0.        ],\n",
       "         [1.1360202 , 0.        , 0.05105412, ..., 0.        ,\n",
       "          1.1299024 , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.1724782 , ..., 0.        ,\n",
       "          1.5050967 , 0.        ],\n",
       "         [0.21820855, 0.        , 0.        , ..., 0.        ,\n",
       "          1.5981531 , 0.        ],\n",
       "         [1.0336637 , 0.        , 0.        , ..., 0.        ,\n",
       "          0.58874226, 0.        ],\n",
       "         [1.1317494 , 0.        , 0.11316407, ..., 0.        ,\n",
       "          1.3520744 , 0.        ]],\n",
       "\n",
       "        [[1.043165  , 0.        , 0.27420557, ..., 0.        ,\n",
       "          1.0304384 , 0.        ],\n",
       "         [0.6525948 , 0.        , 0.14852917, ..., 0.        ,\n",
       "          1.1129901 , 0.        ],\n",
       "         [0.9892204 , 0.        , 0.36337882, ..., 0.        ,\n",
       "          1.0894711 , 0.        ],\n",
       "         [1.0037127 , 0.        , 0.15247786, ..., 0.        ,\n",
       "          1.1887696 , 0.        ]],\n",
       "\n",
       "        [[0.4914289 , 0.        , 0.59826756, ..., 0.        ,\n",
       "          1.3534268 , 0.        ],\n",
       "         [0.17968798, 0.        , 0.4767516 , ..., 0.        ,\n",
       "          1.2029086 , 0.        ],\n",
       "         [0.34820834, 0.        , 0.4092558 , ..., 0.        ,\n",
       "          1.0920638 , 0.        ],\n",
       "         [0.30857566, 0.        , 0.16064072, ..., 0.        ,\n",
       "          0.68576664, 0.        ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.84397036, 0.        , 0.        , ..., 0.        ,\n",
       "          1.0610819 , 0.        ],\n",
       "         [0.7259581 , 0.        , 0.15142307, ..., 0.        ,\n",
       "          0.91879255, 0.        ],\n",
       "         [0.341374  , 0.        , 0.59748244, ..., 0.        ,\n",
       "          0.7589523 , 0.        ],\n",
       "         [0.24433255, 0.        , 0.70576566, ..., 0.        ,\n",
       "          1.0345091 , 0.        ]],\n",
       "\n",
       "        [[0.84576774, 0.        , 0.        , ..., 0.        ,\n",
       "          0.9846159 , 0.        ],\n",
       "         [0.7170024 , 0.        , 1.4961832 , ..., 0.        ,\n",
       "          0.8043147 , 0.        ],\n",
       "         [0.32545805, 0.        , 1.553628  , ..., 0.        ,\n",
       "          0.33043808, 0.        ],\n",
       "         [0.7211053 , 0.        , 0.8649005 , ..., 0.        ,\n",
       "          0.6242335 , 0.        ]],\n",
       "\n",
       "        [[0.46165282, 0.        , 0.99702305, ..., 0.        ,\n",
       "          0.99886715, 0.        ],\n",
       "         [0.74238217, 0.        , 1.9485259 , ..., 0.34824815,\n",
       "          0.2327888 , 0.        ],\n",
       "         [1.0265139 , 0.        , 1.4570627 , ..., 0.49371943,\n",
       "          0.39001408, 0.        ],\n",
       "         [0.6400983 , 0.        , 0.2140069 , ..., 0.0514606 ,\n",
       "          0.37574118, 0.        ]],\n",
       "\n",
       "        [[0.15344197, 0.        , 0.84104943, ..., 0.        ,\n",
       "          1.188564  , 0.        ],\n",
       "         [0.5192561 , 0.        , 1.2276623 , ..., 0.09132317,\n",
       "          0.82417595, 0.        ],\n",
       "         [0.9880264 , 0.        , 0.92619926, ..., 0.27502957,\n",
       "          0.7591052 , 0.        ],\n",
       "         [0.5537271 , 0.        , 0.3187049 , ..., 0.        ,\n",
       "          0.79437166, 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.03259969, 0.        , 0.        , ..., 0.        ,\n",
       "          1.4474211 , 0.        ],\n",
       "         [0.0381341 , 0.        , 0.11279893, ..., 0.34846598,\n",
       "          1.3459058 , 0.        ],\n",
       "         [0.03006291, 0.        , 0.5590201 , ..., 0.276536  ,\n",
       "          1.4235011 , 0.        ],\n",
       "         [0.05175358, 0.        , 0.62343395, ..., 0.        ,\n",
       "          1.2501395 , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.37952954, ..., 0.00518874,\n",
       "          1.3847725 , 0.        ],\n",
       "         [0.33896917, 0.        , 0.2436555 , ..., 0.64501786,\n",
       "          1.4799254 , 0.        ],\n",
       "         [0.5493691 , 0.        , 0.5588163 , ..., 0.46299866,\n",
       "          1.4333007 , 0.        ],\n",
       "         [0.14288664, 0.        , 0.5317836 , ..., 0.01292896,\n",
       "          1.2966707 , 0.        ]],\n",
       "\n",
       "        [[0.30685163, 0.        , 0.27627817, ..., 0.11066245,\n",
       "          1.0572608 , 0.        ],\n",
       "         [1.0489118 , 0.        , 0.22250831, ..., 0.28098658,\n",
       "          0.9487368 , 0.        ],\n",
       "         [0.98889637, 0.        , 0.6642364 , ..., 0.06547598,\n",
       "          0.39087754, 0.        ],\n",
       "         [0.20536113, 0.        , 0.84142184, ..., 0.        ,\n",
       "          0.6930669 , 0.        ]],\n",
       "\n",
       "        [[1.14747   , 0.        , 0.12743741, ..., 0.        ,\n",
       "          0.97559136, 0.        ],\n",
       "         [1.4583973 , 0.        , 0.        , ..., 0.        ,\n",
       "          0.08503622, 0.        ],\n",
       "         [1.1417466 , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.68789613, 0.        , 0.73085475, ..., 0.        ,\n",
       "          0.28681672, 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[1.320155  , 0.        , 0.        , ..., 0.        ,\n",
       "          0.16491085, 0.        ],\n",
       "         [0.36627603, 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.12289932, 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       "\n",
       "        [[1.2377902 , 0.        , 0.022811  , ..., 0.        ,\n",
       "          0.6857118 , 0.        ],\n",
       "         [0.2832985 , 0.        , 0.22688091, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.35830313, 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.6956206 , 0.        , 0.03052884, ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.15000474, ..., 0.        ,\n",
       "          0.8224389 , 0.        ],\n",
       "         [0.        , 0.        , 0.57975936, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.0125736 , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.75651664, 0.        ],\n",
       "         [0.4514066 , 0.        , 0.32586312, ..., 0.        ,\n",
       "          0.19152927, 0.        ],\n",
       "         [0.9480183 , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.84538114, 0.        , 0.        , ..., 0.        ,\n",
       "          0.1533047 , 0.        ]]]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = np.load(open('model/bottleneck_features_train.npy', 'rb'))\n",
    "valid_data = np.load(open('model/bottleneck_features_valid.npy', 'rb'))\n",
    "valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ee65e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_cockroach': 4356,\n",
       " 'train_etc': 3425,\n",
       " 'train_spider': 7908,\n",
       " 'test_cockroach': 1074,\n",
       " 'test_etc': 3864,\n",
       " 'test_spider': 2006,\n",
       " 'valid_cockroach': 1064,\n",
       " 'valid_etc': 3924,\n",
       " 'valid_spider': 1966}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[4356, 3425, 7908, 1074, 3864, 2006, 1064, 3924, 1966]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['train_cockroach',\n",
       " 'train_etc',\n",
       " 'train_spider',\n",
       " 'test_cockroach',\n",
       " 'test_etc',\n",
       " 'test_spider',\n",
       " 'valid_cockroach',\n",
       " 'valid_etc',\n",
       " 'valid_spider']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts\n",
    "list(label_counts.values())\n",
    "list(label_counts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f78e7850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15680, 4, 4, 512)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(15680,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2304, 4, 4, 512)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2304,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = np.array([0] * label_counts['train_cockroach'] +\n",
    "                       [1] * label_counts['train_etc'] +\n",
    "                       [2] * (label_counts['train_spider']-9))\n",
    "valid_labels = np.array([0] * (label_counts['valid_cockroach']//3) +\n",
    "                       [1] * (label_counts['valid_etc']//3 )+\n",
    "                       [2] * (label_counts['valid_spider']//3-13))\n",
    "train_data.shape\n",
    "train_labels.shape\n",
    "valid_data.shape\n",
    "valid_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "669aea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = to_categorical(train_labels, 3)\n",
    "valid_labels = to_categorical(valid_labels, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7fa00e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = Sequential()\n",
    "vgg_model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "vgg_model.add(Dense(256, activation='relu'))\n",
    "vgg_model.add(Dropout(0.4))\n",
    "vgg_model.add(Dense(64, activation='relu'))\n",
    "vgg_model.add(Dropout(0.4))\n",
    "vgg_model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c1b7b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "980/980 [==============================] - 10s 4ms/step - loss: 1.1570 - accuracy: 0.4584 - val_loss: 1.2339 - val_accuracy: 0.2786\n",
      "Epoch 2/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0317 - accuracy: 0.5096 - val_loss: 1.2431 - val_accuracy: 0.2786\n",
      "Epoch 3/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0396 - accuracy: 0.4985 - val_loss: 1.2596 - val_accuracy: 0.2786\n",
      "Epoch 4/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0343 - accuracy: 0.5044 - val_loss: 1.2391 - val_accuracy: 0.2786s: 1.0343 - accuracy\n",
      "Epoch 5/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0393 - accuracy: 0.4956 - val_loss: 1.2601 - val_accuracy: 0.2786\n",
      "Epoch 6/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0323 - accuracy: 0.5060 - val_loss: 1.2226 - val_accuracy: 0.2786\n",
      "Epoch 7/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0372 - accuracy: 0.4998 - val_loss: 1.2457 - val_accuracy: 0.2786\n",
      "Epoch 8/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0277 - accuracy: 0.5111 - val_loss: 1.2363 - val_accuracy: 0.2786\n",
      "Epoch 9/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0331 - accuracy: 0.5071 - val_loss: 1.2409 - val_accuracy: 0.2786\n",
      "Epoch 10/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0343 - accuracy: 0.5042 - val_loss: 1.2641 - val_accuracy: 0.2786\n",
      "Epoch 11/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0360 - accuracy: 0.5011 - val_loss: 1.2353 - val_accuracy: 0.2786\n",
      "Epoch 12/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0326 - accuracy: 0.5056 - val_loss: 1.2489 - val_accuracy: 0.2786\n",
      "Epoch 13/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0359 - accuracy: 0.5015 - val_loss: 1.2457 - val_accuracy: 0.2786\n",
      "Epoch 14/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0371 - accuracy: 0.4990 - val_loss: 1.2609 - val_accuracy: 0.2786\n",
      "Epoch 15/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0341 - accuracy: 0.5032 - val_loss: 1.2545 - val_accuracy: 0.2786\n",
      "Epoch 16/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0301 - accuracy: 0.5068 - val_loss: 1.2342 - val_accuracy: 0.2786\n",
      "Epoch 17/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0288 - accuracy: 0.5109 - val_loss: 1.2440 - val_accuracy: 0.2786\n",
      "Epoch 18/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0362 - accuracy: 0.4991 - val_loss: 1.2581 - val_accuracy: 0.2786\n",
      "Epoch 19/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0326 - accuracy: 0.5037 - val_loss: 1.2422 - val_accuracy: 0.2786\n",
      "Epoch 20/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0370 - accuracy: 0.4995 - val_loss: 1.2538 - val_accuracy: 0.2791\n",
      "Epoch 21/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0309 - accuracy: 0.5070 - val_loss: 1.2472 - val_accuracy: 0.2786\n",
      "Epoch 22/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0331 - accuracy: 0.5044 - val_loss: 1.2509 - val_accuracy: 0.2791\n",
      "Epoch 23/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0361 - accuracy: 0.5014 - val_loss: 1.2560 - val_accuracy: 0.2791\n",
      "Epoch 24/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0297 - accuracy: 0.5078 - val_loss: 1.2777 - val_accuracy: 0.2713\n",
      "Epoch 25/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0337 - accuracy: 0.5034 - val_loss: 1.2506 - val_accuracy: 0.2786\n",
      "Epoch 26/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0344 - accuracy: 0.5020 - val_loss: 1.2520 - val_accuracy: 0.2786\n",
      "Epoch 27/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0326 - accuracy: 0.5025 - val_loss: 1.2494 - val_accuracy: 0.2786\n",
      "Epoch 28/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0325 - accuracy: 0.5041 - val_loss: 1.2629 - val_accuracy: 0.2786\n",
      "Epoch 29/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0293 - accuracy: 0.5067 - val_loss: 1.2555 - val_accuracy: 0.2786\n",
      "Epoch 30/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0314 - accuracy: 0.5040 - val_loss: 1.2602 - val_accuracy: 0.2786\n",
      "Epoch 31/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0263 - accuracy: 0.5083 - val_loss: 1.2534 - val_accuracy: 0.2786\n",
      "Epoch 32/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0280 - accuracy: 0.5057 - val_loss: 1.2480 - val_accuracy: 0.2786\n",
      "Epoch 33/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0308 - accuracy: 0.5049 - val_loss: 1.2501 - val_accuracy: 0.2786\n",
      "Epoch 34/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0325 - accuracy: 0.5011 - val_loss: 1.2523 - val_accuracy: 0.2786\n",
      "Epoch 35/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0324 - accuracy: 0.5004 - val_loss: 1.2690 - val_accuracy: 0.2786\n",
      "Epoch 36/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0314 - accuracy: 0.5065 - val_loss: 1.2553 - val_accuracy: 0.2786\n",
      "Epoch 37/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0262 - accuracy: 0.5113 - val_loss: 1.2669 - val_accuracy: 0.2799\n",
      "Epoch 38/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0328 - accuracy: 0.4996 - val_loss: 1.2864 - val_accuracy: 0.2786\n",
      "Epoch 39/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0279 - accuracy: 0.5037 - val_loss: 1.2549 - val_accuracy: 0.2786\n",
      "Epoch 40/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0263 - accuracy: 0.5088 - val_loss: 1.2668 - val_accuracy: 0.2786\n",
      "Epoch 41/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0247 - accuracy: 0.5096 - val_loss: 1.2957 - val_accuracy: 0.2786\n",
      "Epoch 42/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0281 - accuracy: 0.5065 - val_loss: 1.2874 - val_accuracy: 0.2786\n",
      "Epoch 43/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0274 - accuracy: 0.5068 - val_loss: 1.2799 - val_accuracy: 0.2786\n",
      "Epoch 44/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0281 - accuracy: 0.5045 - val_loss: 1.2977 - val_accuracy: 0.2786\n",
      "Epoch 45/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0263 - accuracy: 0.5053 - val_loss: 1.2913 - val_accuracy: 0.2786\n",
      "Epoch 46/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0239 - accuracy: 0.5097 - val_loss: 1.2942 - val_accuracy: 0.2786\n",
      "Epoch 47/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0244 - accuracy: 0.5087 - val_loss: 1.2810 - val_accuracy: 0.2786\n",
      "Epoch 48/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0291 - accuracy: 0.5037 - val_loss: 1.3116 - val_accuracy: 0.2786\n",
      "Epoch 49/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0278 - accuracy: 0.5040 - val_loss: 1.2966 - val_accuracy: 0.2786\n",
      "Epoch 50/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0239 - accuracy: 0.5055 - val_loss: 1.3076 - val_accuracy: 0.2786\n",
      "Epoch 51/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0291 - accuracy: 0.4985 - val_loss: 1.2817 - val_accuracy: 0.2786\n",
      "Epoch 52/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0269 - accuracy: 0.5041 - val_loss: 1.2723 - val_accuracy: 0.2786\n",
      "Epoch 53/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0249 - accuracy: 0.5073 - val_loss: 1.3585 - val_accuracy: 0.2786\n",
      "Epoch 54/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0225 - accuracy: 0.5090 - val_loss: 1.3164 - val_accuracy: 0.2786\n",
      "Epoch 55/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0257 - accuracy: 0.5027 - val_loss: 1.3529 - val_accuracy: 0.2786\n",
      "Epoch 56/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0328 - accuracy: 0.4997 - val_loss: 1.3869 - val_accuracy: 0.2786\n",
      "Epoch 57/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0226 - accuracy: 0.5071 - val_loss: 1.3363 - val_accuracy: 0.2786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0289 - accuracy: 0.5006 - val_loss: 1.4077 - val_accuracy: 0.2786\n",
      "Epoch 59/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0226 - accuracy: 0.5075 - val_loss: 1.4000 - val_accuracy: 0.2786\n",
      "Epoch 60/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0274 - accuracy: 0.5014 - val_loss: 1.4582 - val_accuracy: 0.2786\n",
      "Epoch 61/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0278 - accuracy: 0.5012 - val_loss: 1.3887 - val_accuracy: 0.2786\n",
      "Epoch 62/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0226 - accuracy: 0.5080 - val_loss: 1.3773 - val_accuracy: 0.2786.0224 - \n",
      "Epoch 63/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0336 - accuracy: 0.4949 - val_loss: 1.3964 - val_accuracy: 0.2786\n",
      "Epoch 64/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0232 - accuracy: 0.5084 - val_loss: 1.3657 - val_accuracy: 0.2786\n",
      "Epoch 65/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0223 - accuracy: 0.5055 - val_loss: 1.3385 - val_accuracy: 0.2786\n",
      "Epoch 66/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0222 - accuracy: 0.5063 - val_loss: 1.4331 - val_accuracy: 0.2786\n",
      "Epoch 67/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0311 - accuracy: 0.4977 - val_loss: 1.4602 - val_accuracy: 0.2786\n",
      "Epoch 68/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0259 - accuracy: 0.5038 - val_loss: 1.4812 - val_accuracy: 0.2786\n",
      "Epoch 69/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0217 - accuracy: 0.5105 - val_loss: 1.4060 - val_accuracy: 0.2786\n",
      "Epoch 70/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0277 - accuracy: 0.5002 - val_loss: 1.5029 - val_accuracy: 0.2786\n",
      "Epoch 71/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0170 - accuracy: 0.5141 - val_loss: 1.4744 - val_accuracy: 0.2786\n",
      "Epoch 72/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0261 - accuracy: 0.5005 - val_loss: 1.5150 - val_accuracy: 0.2786\n",
      "Epoch 73/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0269 - accuracy: 0.5016 - val_loss: 1.5545 - val_accuracy: 0.2786\n",
      "Epoch 74/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0275 - accuracy: 0.4999 - val_loss: 1.5386 - val_accuracy: 0.2786\n",
      "Epoch 75/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0310 - accuracy: 0.4965 - val_loss: 1.4783 - val_accuracy: 0.2786\n",
      "Epoch 76/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0248 - accuracy: 0.5045 - val_loss: 1.7257 - val_accuracy: 0.2786\n",
      "Epoch 77/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0255 - accuracy: 0.5041 - val_loss: 1.7197 - val_accuracy: 0.2786\n",
      "Epoch 78/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0258 - accuracy: 0.5041 - val_loss: 1.7320 - val_accuracy: 0.2786\n",
      "Epoch 79/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0223 - accuracy: 0.5095 - val_loss: 1.4914 - val_accuracy: 0.2786\n",
      "Epoch 80/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0274 - accuracy: 0.5016 - val_loss: 1.4796 - val_accuracy: 0.2786\n",
      "Epoch 81/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0242 - accuracy: 0.5053 - val_loss: 1.6374 - val_accuracy: 0.2786\n",
      "Epoch 82/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0267 - accuracy: 0.5028 - val_loss: 1.6318 - val_accuracy: 0.2786\n",
      "Epoch 83/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0248 - accuracy: 0.5020 - val_loss: 1.7066 - val_accuracy: 0.2786\n",
      "Epoch 84/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0164 - accuracy: 0.5133 - val_loss: 1.7014 - val_accuracy: 0.2786\n",
      "Epoch 85/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0258 - accuracy: 0.5023 - val_loss: 1.6808 - val_accuracy: 0.2786\n",
      "Epoch 86/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0238 - accuracy: 0.5067 - val_loss: 1.6895 - val_accuracy: 0.2786\n",
      "Epoch 87/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0287 - accuracy: 0.4996 - val_loss: 1.7515 - val_accuracy: 0.2786\n",
      "Epoch 88/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0268 - accuracy: 0.5031 - val_loss: 1.6409 - val_accuracy: 0.2786\n",
      "Epoch 89/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0248 - accuracy: 0.5010 - val_loss: 1.7735 - val_accuracy: 0.2786\n",
      "Epoch 90/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0289 - accuracy: 0.4998 - val_loss: 1.5312 - val_accuracy: 0.2786\n",
      "Epoch 91/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0233 - accuracy: 0.5034 - val_loss: 1.4433 - val_accuracy: 0.2786\n",
      "Epoch 92/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0237 - accuracy: 0.5056 - val_loss: 1.7123 - val_accuracy: 0.2786\n",
      "Epoch 93/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0156 - accuracy: 0.5153 - val_loss: 1.4157 - val_accuracy: 0.2786\n",
      "Epoch 94/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0272 - accuracy: 0.5000 - val_loss: 1.4294 - val_accuracy: 0.2786\n",
      "Epoch 95/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0309 - accuracy: 0.4992 - val_loss: 1.8356 - val_accuracy: 0.2786\n",
      "Epoch 96/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0236 - accuracy: 0.5030 - val_loss: 1.5776 - val_accuracy: 0.2786\n",
      "Epoch 97/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0303 - accuracy: 0.4958 - val_loss: 1.7102 - val_accuracy: 0.2786\n",
      "Epoch 98/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0226 - accuracy: 0.5068 - val_loss: 1.7355 - val_accuracy: 0.2786\n",
      "Epoch 99/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0226 - accuracy: 0.5063 - val_loss: 1.8196 - val_accuracy: 0.2786\n",
      "Epoch 100/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0230 - accuracy: 0.5059 - val_loss: 1.6463 - val_accuracy: 0.2786\n",
      "Epoch 101/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0227 - accuracy: 0.5063 - val_loss: 1.8342 - val_accuracy: 0.2786\n",
      "Epoch 102/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0252 - accuracy: 0.5002 - val_loss: 1.7860 - val_accuracy: 0.2786\n",
      "Epoch 103/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0263 - accuracy: 0.5016 - val_loss: 1.5777 - val_accuracy: 0.2786\n",
      "Epoch 104/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0312 - accuracy: 0.4967 - val_loss: 1.6818 - val_accuracy: 0.2786\n",
      "Epoch 105/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0265 - accuracy: 0.5059 - val_loss: 1.6910 - val_accuracy: 0.2786\n",
      "Epoch 106/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0166 - accuracy: 0.5114 - val_loss: 1.6526 - val_accuracy: 0.2786\n",
      "Epoch 107/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0249 - accuracy: 0.5041 - val_loss: 2.0131 - val_accuracy: 0.2786\n",
      "Epoch 108/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0224 - accuracy: 0.5074 - val_loss: 1.7569 - val_accuracy: 0.2786\n",
      "Epoch 109/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0243 - accuracy: 0.5034 - val_loss: 1.7710 - val_accuracy: 0.2786\n",
      "Epoch 110/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0205 - accuracy: 0.5081 - val_loss: 1.7844 - val_accuracy: 0.2786\n",
      "Epoch 111/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0243 - accuracy: 0.5032 - val_loss: 1.6969 - val_accuracy: 0.2786\n",
      "Epoch 112/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0218 - accuracy: 0.5096 - val_loss: 1.7947 - val_accuracy: 0.2786\n",
      "Epoch 113/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0261 - accuracy: 0.5018 - val_loss: 1.9536 - val_accuracy: 0.2786\n",
      "Epoch 114/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0278 - accuracy: 0.4991 - val_loss: 1.8532 - val_accuracy: 0.2786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0244 - accuracy: 0.5033 - val_loss: 1.8340 - val_accuracy: 0.2786\n",
      "Epoch 116/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0244 - accuracy: 0.5011 - val_loss: 1.9829 - val_accuracy: 0.2786\n",
      "Epoch 117/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0206 - accuracy: 0.5069 - val_loss: 1.7640 - val_accuracy: 0.2786\n",
      "Epoch 118/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0226 - accuracy: 0.5078 - val_loss: 1.7277 - val_accuracy: 0.2786\n",
      "Epoch 119/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0216 - accuracy: 0.5086 - val_loss: 1.8532 - val_accuracy: 0.2786\n",
      "Epoch 120/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0280 - accuracy: 0.4970 - val_loss: 1.7950 - val_accuracy: 0.2786\n",
      "Epoch 121/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0255 - accuracy: 0.5032 - val_loss: 1.8569 - val_accuracy: 0.2786\n",
      "Epoch 122/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0216 - accuracy: 0.5061 - val_loss: 1.6443 - val_accuracy: 0.2786\n",
      "Epoch 123/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0254 - accuracy: 0.5016 - val_loss: 1.8936 - val_accuracy: 0.2786\n",
      "Epoch 124/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0212 - accuracy: 0.5059 - val_loss: 1.9149 - val_accuracy: 0.2786\n",
      "Epoch 125/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0308 - accuracy: 0.4956 - val_loss: 1.9599 - val_accuracy: 0.2786\n",
      "Epoch 126/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0258 - accuracy: 0.4982 - val_loss: 2.0355 - val_accuracy: 0.2786\n",
      "Epoch 127/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0226 - accuracy: 0.5073 - val_loss: 1.7812 - val_accuracy: 0.2786\n",
      "Epoch 128/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0231 - accuracy: 0.5037 - val_loss: 1.7923 - val_accuracy: 0.2786\n",
      "Epoch 129/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0147 - accuracy: 0.5123 - val_loss: 1.7212 - val_accuracy: 0.2786\n",
      "Epoch 130/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0252 - accuracy: 0.5032 - val_loss: 1.9712 - val_accuracy: 0.2786\n",
      "Epoch 131/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0295 - accuracy: 0.4971 - val_loss: 1.7943 - val_accuracy: 0.2786\n",
      "Epoch 132/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0190 - accuracy: 0.5080 - val_loss: 1.9900 - val_accuracy: 0.2786\n",
      "Epoch 133/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0223 - accuracy: 0.5015 - val_loss: 2.0294 - val_accuracy: 0.2786\n",
      "Epoch 134/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0240 - accuracy: 0.5029 - val_loss: 2.0854 - val_accuracy: 0.2786\n",
      "Epoch 135/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0197 - accuracy: 0.5099 - val_loss: 2.0531 - val_accuracy: 0.2786\n",
      "Epoch 136/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0202 - accuracy: 0.5080 - val_loss: 2.0146 - val_accuracy: 0.2786\n",
      "Epoch 137/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0234 - accuracy: 0.5053 - val_loss: 2.0239 - val_accuracy: 0.2786\n",
      "Epoch 138/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0203 - accuracy: 0.5081 - val_loss: 1.9265 - val_accuracy: 0.2786\n",
      "Epoch 139/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0178 - accuracy: 0.5111 - val_loss: 1.9605 - val_accuracy: 0.2786\n",
      "Epoch 140/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0214 - accuracy: 0.5034 - val_loss: 2.1455 - val_accuracy: 0.2786\n",
      "Epoch 141/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0202 - accuracy: 0.5081 - val_loss: 2.0410 - val_accuracy: 0.2786\n",
      "Epoch 142/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0200 - accuracy: 0.5053 - val_loss: 2.0169 - val_accuracy: 0.2786\n",
      "Epoch 143/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0230 - accuracy: 0.5042 - val_loss: 2.1412 - val_accuracy: 0.2786\n",
      "Epoch 144/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0238 - accuracy: 0.5040 - val_loss: 2.0497 - val_accuracy: 0.2786\n",
      "Epoch 145/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0252 - accuracy: 0.5004 - val_loss: 1.9981 - val_accuracy: 0.2786\n",
      "Epoch 146/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0250 - accuracy: 0.5039 - val_loss: 1.9760 - val_accuracy: 0.2786\n",
      "Epoch 147/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0237 - accuracy: 0.5013 - val_loss: 2.1901 - val_accuracy: 0.2786\n",
      "Epoch 148/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0214 - accuracy: 0.5051 - val_loss: 2.1154 - val_accuracy: 0.2786\n",
      "Epoch 149/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0246 - accuracy: 0.4992 - val_loss: 1.9866 - val_accuracy: 0.2786\n",
      "Epoch 150/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0188 - accuracy: 0.5101 - val_loss: 2.2137 - val_accuracy: 0.2786\n",
      "Epoch 151/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0197 - accuracy: 0.5077 - val_loss: 2.0864 - val_accuracy: 0.2786\n",
      "Epoch 152/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0215 - accuracy: 0.5027 - val_loss: 2.4417 - val_accuracy: 0.2786\n",
      "Epoch 153/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0258 - accuracy: 0.4992 - val_loss: 2.3910 - val_accuracy: 0.2786\n",
      "Epoch 154/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0200 - accuracy: 0.5059 - val_loss: 2.1626 - val_accuracy: 0.2786\n",
      "Epoch 155/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0210 - accuracy: 0.5077 - val_loss: 2.4426 - val_accuracy: 0.2786\n",
      "Epoch 156/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0186 - accuracy: 0.5084 - val_loss: 2.3157 - val_accuracy: 0.2786\n",
      "Epoch 157/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0167 - accuracy: 0.5127 - val_loss: 2.7846 - val_accuracy: 0.2786\n",
      "Epoch 158/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0284 - accuracy: 0.5015 - val_loss: 2.1186 - val_accuracy: 0.2786\n",
      "Epoch 159/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0286 - accuracy: 0.4955 - val_loss: 2.2974 - val_accuracy: 0.2786\n",
      "Epoch 160/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0170 - accuracy: 0.5097 - val_loss: 2.5309 - val_accuracy: 0.2786\n",
      "Epoch 161/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0205 - accuracy: 0.5087 - val_loss: 2.4188 - val_accuracy: 0.2786\n",
      "Epoch 162/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0209 - accuracy: 0.5078 - val_loss: 3.1979 - val_accuracy: 0.2786\n",
      "Epoch 163/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0194 - accuracy: 0.5115 - val_loss: 2.8260 - val_accuracy: 0.2786\n",
      "Epoch 164/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0203 - accuracy: 0.5091 - val_loss: 3.0819 - val_accuracy: 0.2786\n",
      "Epoch 165/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0237 - accuracy: 0.5025 - val_loss: 2.8228 - val_accuracy: 0.2786\n",
      "Epoch 166/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0277 - accuracy: 0.4984 - val_loss: 3.1251 - val_accuracy: 0.2786\n",
      "Epoch 167/400\n",
      "980/980 [==============================] - 8s 8ms/step - loss: 1.0256 - accuracy: 0.5026 - val_loss: 2.6577 - val_accuracy: 0.2786\n",
      "Epoch 168/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0179 - accuracy: 0.5116 - val_loss: 2.9399 - val_accuracy: 0.2786\n",
      "Epoch 169/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0274 - accuracy: 0.4998 - val_loss: 2.6318 - val_accuracy: 0.2786\n",
      "Epoch 170/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0300 - accuracy: 0.4950 - val_loss: 2.2236 - val_accuracy: 0.2786\n",
      "Epoch 171/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0248 - accuracy: 0.5038 - val_loss: 2.8216 - val_accuracy: 0.2786\n",
      "Epoch 172/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0270 - accuracy: 0.4977 - val_loss: 2.8806 - val_accuracy: 0.2786\n",
      "Epoch 173/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0262 - accuracy: 0.5009 - val_loss: 2.3041 - val_accuracy: 0.2786\n",
      "Epoch 174/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0198 - accuracy: 0.5081 - val_loss: 2.9803 - val_accuracy: 0.2791\n",
      "Epoch 175/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0246 - accuracy: 0.5009 - val_loss: 2.8919 - val_accuracy: 0.2786\n",
      "Epoch 176/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0228 - accuracy: 0.5025 - val_loss: 2.4522 - val_accuracy: 0.2786\n",
      "Epoch 177/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0266 - accuracy: 0.4987 - val_loss: 2.8753 - val_accuracy: 0.2786\n",
      "Epoch 178/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0230 - accuracy: 0.5037 - val_loss: 2.8129 - val_accuracy: 0.2786\n",
      "Epoch 179/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0260 - accuracy: 0.5002 - val_loss: 2.7234 - val_accuracy: 0.2786\n",
      "Epoch 180/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0177 - accuracy: 0.5087 - val_loss: 3.3534 - val_accuracy: 0.2786\n",
      "Epoch 181/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0231 - accuracy: 0.5034 - val_loss: 2.5595 - val_accuracy: 0.2786\n",
      "Epoch 182/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0205 - accuracy: 0.5057 - val_loss: 2.5907 - val_accuracy: 0.2786\n",
      "Epoch 183/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0250 - accuracy: 0.5013 - val_loss: 2.8788 - val_accuracy: 0.2786\n",
      "Epoch 184/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0227 - accuracy: 0.5036 - val_loss: 3.0882 - val_accuracy: 0.2786\n",
      "Epoch 185/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0188 - accuracy: 0.5090 - val_loss: 2.6185 - val_accuracy: 0.2786\n",
      "Epoch 186/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0190 - accuracy: 0.5072 - val_loss: 3.1988 - val_accuracy: 0.2786\n",
      "Epoch 187/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0222 - accuracy: 0.5044 - val_loss: 3.2239 - val_accuracy: 0.2786\n",
      "Epoch 188/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0232 - accuracy: 0.5026 - val_loss: 3.3563 - val_accuracy: 0.2786\n",
      "Epoch 189/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0184 - accuracy: 0.5098 - val_loss: 2.2636 - val_accuracy: 0.2786\n",
      "Epoch 190/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0227 - accuracy: 0.5072 - val_loss: 2.3723 - val_accuracy: 0.2786\n",
      "Epoch 191/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0198 - accuracy: 0.5110 - val_loss: 2.5047 - val_accuracy: 0.2786\n",
      "Epoch 192/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0186 - accuracy: 0.5117 - val_loss: 3.1215 - val_accuracy: 0.2786\n",
      "Epoch 193/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0224 - accuracy: 0.5055 - val_loss: 2.9064 - val_accuracy: 0.2795\n",
      "Epoch 194/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0239 - accuracy: 0.5011 - val_loss: 2.8389 - val_accuracy: 0.2786\n",
      "Epoch 195/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0191 - accuracy: 0.5105 - val_loss: 2.7813 - val_accuracy: 0.2786\n",
      "Epoch 196/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0240 - accuracy: 0.5002 - val_loss: 2.6014 - val_accuracy: 0.2786\n",
      "Epoch 197/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0209 - accuracy: 0.5071 - val_loss: 2.5665 - val_accuracy: 0.2786\n",
      "Epoch 198/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0237 - accuracy: 0.5024 - val_loss: 3.3020 - val_accuracy: 0.2786\n",
      "Epoch 199/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0257 - accuracy: 0.5007 - val_loss: 2.7489 - val_accuracy: 0.2786\n",
      "Epoch 200/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0215 - accuracy: 0.5058 - val_loss: 3.2418 - val_accuracy: 0.2786\n",
      "Epoch 201/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0224 - accuracy: 0.5032 - val_loss: 3.3413 - val_accuracy: 0.2786\n",
      "Epoch 202/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0207 - accuracy: 0.5055 - val_loss: 2.9267 - val_accuracy: 0.2786\n",
      "Epoch 203/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0188 - accuracy: 0.5104 - val_loss: 2.6058 - val_accuracy: 0.2786\n",
      "Epoch 204/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0240 - accuracy: 0.5023 - val_loss: 2.9957 - val_accuracy: 0.2786\n",
      "Epoch 205/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0238 - accuracy: 0.5021 - val_loss: 3.4088 - val_accuracy: 0.2786\n",
      "Epoch 206/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0198 - accuracy: 0.5065 - val_loss: 3.5076 - val_accuracy: 0.2786\n",
      "Epoch 207/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0215 - accuracy: 0.5061 - val_loss: 3.2998 - val_accuracy: 0.2786\n",
      "Epoch 208/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0220 - accuracy: 0.5075 - val_loss: 3.5571 - val_accuracy: 0.2786\n",
      "Epoch 209/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0217 - accuracy: 0.5106 - val_loss: 3.4929 - val_accuracy: 0.2786\n",
      "Epoch 210/400\n",
      "980/980 [==============================] - 6s 6ms/step - loss: 1.0206 - accuracy: 0.5073 - val_loss: 3.7499 - val_accuracy: 0.2786\n",
      "Epoch 211/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0239 - accuracy: 0.5063 - val_loss: 3.4237 - val_accuracy: 0.2786\n",
      "Epoch 212/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0243 - accuracy: 0.4995 - val_loss: 2.8732 - val_accuracy: 0.2786\n",
      "Epoch 213/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0252 - accuracy: 0.5002 - val_loss: 3.3548 - val_accuracy: 0.2786\n",
      "Epoch 214/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0260 - accuracy: 0.5045 - val_loss: 3.5934 - val_accuracy: 0.2786\n",
      "Epoch 215/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0200 - accuracy: 0.5049 - val_loss: 3.3423 - val_accuracy: 0.2786\n",
      "Epoch 216/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0227 - accuracy: 0.5022 - val_loss: 3.6290 - val_accuracy: 0.2786\n",
      "Epoch 217/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0268 - accuracy: 0.4982 - val_loss: 2.7889 - val_accuracy: 0.2786\n",
      "Epoch 218/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0227 - accuracy: 0.5060 - val_loss: 2.6192 - val_accuracy: 0.2786\n",
      "Epoch 219/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0226 - accuracy: 0.5037 - val_loss: 2.9228 - val_accuracy: 0.2786\n",
      "Epoch 220/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0248 - accuracy: 0.4993 - val_loss: 3.5489 - val_accuracy: 0.2786\n",
      "Epoch 221/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0196 - accuracy: 0.5060 - val_loss: 3.3797 - val_accuracy: 0.2786\n",
      "Epoch 222/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0219 - accuracy: 0.5053 - val_loss: 3.2034 - val_accuracy: 0.2786\n",
      "Epoch 223/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0229 - accuracy: 0.5041 - val_loss: 3.2312 - val_accuracy: 0.2786\n",
      "Epoch 224/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0161 - accuracy: 0.5102 - val_loss: 3.3294 - val_accuracy: 0.2786\n",
      "Epoch 225/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0234 - accuracy: 0.5065 - val_loss: 3.0369 - val_accuracy: 0.2786\n",
      "Epoch 226/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0261 - accuracy: 0.5009 - val_loss: 3.1503 - val_accuracy: 0.2786\n",
      "Epoch 227/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0174 - accuracy: 0.5103 - val_loss: 3.2311 - val_accuracy: 0.2786\n",
      "Epoch 228/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0229 - accuracy: 0.5010 - val_loss: 3.0634 - val_accuracy: 0.2786\n",
      "Epoch 229/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0243 - accuracy: 0.4998 - val_loss: 3.4304 - val_accuracy: 0.2786\n",
      "Epoch 230/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0214 - accuracy: 0.5036 - val_loss: 2.7922 - val_accuracy: 0.2786\n",
      "Epoch 231/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0178 - accuracy: 0.5102 - val_loss: 3.3169 - val_accuracy: 0.2786\n",
      "Epoch 232/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0188 - accuracy: 0.5079 - val_loss: 3.0453 - val_accuracy: 0.2786\n",
      "Epoch 233/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0141 - accuracy: 0.5141 - val_loss: 2.9257 - val_accuracy: 0.2786\n",
      "Epoch 234/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0237 - accuracy: 0.5036 - val_loss: 3.6702 - val_accuracy: 0.2786\n",
      "Epoch 235/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0219 - accuracy: 0.5019 - val_loss: 3.8302 - val_accuracy: 0.2786\n",
      "Epoch 236/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0221 - accuracy: 0.5028 - val_loss: 4.1246 - val_accuracy: 0.2786\n",
      "Epoch 237/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0233 - accuracy: 0.5020 - val_loss: 3.7144 - val_accuracy: 0.2786\n",
      "Epoch 238/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0203 - accuracy: 0.5075 - val_loss: 3.6656 - val_accuracy: 0.2786\n",
      "Epoch 239/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0184 - accuracy: 0.5078 - val_loss: 4.0837 - val_accuracy: 0.2786\n",
      "Epoch 240/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0233 - accuracy: 0.4982 - val_loss: 4.3303 - val_accuracy: 0.2786\n",
      "Epoch 241/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0220 - accuracy: 0.5076 - val_loss: 4.6048 - val_accuracy: 0.2786\n",
      "Epoch 242/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0273 - accuracy: 0.5005 - val_loss: 3.6592 - val_accuracy: 0.2786\n",
      "Epoch 243/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0220 - accuracy: 0.5046 - val_loss: 3.7041 - val_accuracy: 0.2786\n",
      "Epoch 244/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0219 - accuracy: 0.5042 - val_loss: 3.8867 - val_accuracy: 0.2786\n",
      "Epoch 245/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0166 - accuracy: 0.5112 - val_loss: 4.0804 - val_accuracy: 0.2786\n",
      "Epoch 246/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0256 - accuracy: 0.5003 - val_loss: 3.5203 - val_accuracy: 0.2786\n",
      "Epoch 247/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0261 - accuracy: 0.5031 - val_loss: 3.7064 - val_accuracy: 0.2786\n",
      "Epoch 248/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0203 - accuracy: 0.5059 - val_loss: 4.2228 - val_accuracy: 0.2786\n",
      "Epoch 249/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0181 - accuracy: 0.5119 - val_loss: 3.8917 - val_accuracy: 0.2786\n",
      "Epoch 250/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0224 - accuracy: 0.5031 - val_loss: 3.8599 - val_accuracy: 0.2786\n",
      "Epoch 251/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0228 - accuracy: 0.5035 - val_loss: 4.2711 - val_accuracy: 0.2786\n",
      "Epoch 252/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0244 - accuracy: 0.5046 - val_loss: 3.9080 - val_accuracy: 0.2786\n",
      "Epoch 253/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0182 - accuracy: 0.5104 - val_loss: 3.2173 - val_accuracy: 0.2786\n",
      "Epoch 254/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0196 - accuracy: 0.5089 - val_loss: 3.8516 - val_accuracy: 0.2786\n",
      "Epoch 255/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0242 - accuracy: 0.5038 - val_loss: 3.6289 - val_accuracy: 0.2786\n",
      "Epoch 256/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0240 - accuracy: 0.5007 - val_loss: 3.5340 - val_accuracy: 0.2786\n",
      "Epoch 257/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0178 - accuracy: 0.5101 - val_loss: 3.8811 - val_accuracy: 0.2786\n",
      "Epoch 258/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0224 - accuracy: 0.5008 - val_loss: 3.7358 - val_accuracy: 0.2786\n",
      "Epoch 259/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0246 - accuracy: 0.5033 - val_loss: 3.9416 - val_accuracy: 0.2786\n",
      "Epoch 260/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0222 - accuracy: 0.5051 - val_loss: 3.7109 - val_accuracy: 0.2786\n",
      "Epoch 261/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0239 - accuracy: 0.4988 - val_loss: 4.1361 - val_accuracy: 0.2786\n",
      "Epoch 262/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0183 - accuracy: 0.5087 - val_loss: 4.0718 - val_accuracy: 0.2786\n",
      "Epoch 263/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0225 - accuracy: 0.5052 - val_loss: 3.6102 - val_accuracy: 0.2786\n",
      "Epoch 264/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0202 - accuracy: 0.5095 - val_loss: 3.5242 - val_accuracy: 0.2786\n",
      "Epoch 265/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0256 - accuracy: 0.4997 - val_loss: 3.7491 - val_accuracy: 0.2786\n",
      "Epoch 266/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0210 - accuracy: 0.5068 - val_loss: 3.9780 - val_accuracy: 0.2786\n",
      "Epoch 267/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0220 - accuracy: 0.5006 - val_loss: 4.1586 - val_accuracy: 0.2786\n",
      "Epoch 268/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0236 - accuracy: 0.5019 - val_loss: 3.9757 - val_accuracy: 0.2786\n",
      "Epoch 269/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0253 - accuracy: 0.5028 - val_loss: 4.1735 - val_accuracy: 0.2786\n",
      "Epoch 270/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0201 - accuracy: 0.5083 - val_loss: 3.8850 - val_accuracy: 0.2786\n",
      "Epoch 271/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0185 - accuracy: 0.5103 - val_loss: 3.2867 - val_accuracy: 0.2786\n",
      "Epoch 272/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0261 - accuracy: 0.5009 - val_loss: 4.5717 - val_accuracy: 0.2786\n",
      "Epoch 273/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0259 - accuracy: 0.5020 - val_loss: 3.9712 - val_accuracy: 0.2786\n",
      "Epoch 274/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0222 - accuracy: 0.5032 - val_loss: 3.9937 - val_accuracy: 0.2786\n",
      "Epoch 275/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0256 - accuracy: 0.4986 - val_loss: 5.0739 - val_accuracy: 0.2786\n",
      "Epoch 276/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0254 - accuracy: 0.5004 - val_loss: 4.4178 - val_accuracy: 0.2786\n",
      "Epoch 277/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0230 - accuracy: 0.5058 - val_loss: 4.3763 - val_accuracy: 0.2786\n",
      "Epoch 278/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0193 - accuracy: 0.5065 - val_loss: 3.2604 - val_accuracy: 0.2786\n",
      "Epoch 279/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0240 - accuracy: 0.5044 - val_loss: 4.4235 - val_accuracy: 0.2786\n",
      "Epoch 280/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0221 - accuracy: 0.5044 - val_loss: 4.8006 - val_accuracy: 0.2786\n",
      "Epoch 281/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0223 - accuracy: 0.5062 - val_loss: 4.4739 - val_accuracy: 0.2786\n",
      "Epoch 282/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0233 - accuracy: 0.5020 - val_loss: 3.4794 - val_accuracy: 0.2786\n",
      "Epoch 283/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0225 - accuracy: 0.5024 - val_loss: 4.0867 - val_accuracy: 0.2786\n",
      "Epoch 284/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0239 - accuracy: 0.5006 - val_loss: 3.7163 - val_accuracy: 0.2786\n",
      "Epoch 285/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0208 - accuracy: 0.5048 - val_loss: 3.7812 - val_accuracy: 0.2786\n",
      "Epoch 286/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0245 - accuracy: 0.4989 - val_loss: 4.0987 - val_accuracy: 0.2786\n",
      "Epoch 287/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0269 - accuracy: 0.4962 - val_loss: 3.4391 - val_accuracy: 0.2786\n",
      "Epoch 288/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0222 - accuracy: 0.5050 - val_loss: 4.1446 - val_accuracy: 0.2786\n",
      "Epoch 289/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0182 - accuracy: 0.5094 - val_loss: 4.0015 - val_accuracy: 0.2786\n",
      "Epoch 290/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0222 - accuracy: 0.5052 - val_loss: 3.9196 - val_accuracy: 0.2786\n",
      "Epoch 291/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0190 - accuracy: 0.5091 - val_loss: 4.1841 - val_accuracy: 0.2786\n",
      "Epoch 292/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0172 - accuracy: 0.5100 - val_loss: 4.6704 - val_accuracy: 0.2786\n",
      "Epoch 293/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0318 - accuracy: 0.4905 - val_loss: 3.3116 - val_accuracy: 0.2786\n",
      "Epoch 294/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0232 - accuracy: 0.5063 - val_loss: 3.6003 - val_accuracy: 0.2786\n",
      "Epoch 295/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0174 - accuracy: 0.5096 - val_loss: 4.5783 - val_accuracy: 0.2786\n",
      "Epoch 296/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0227 - accuracy: 0.5011 - val_loss: 3.9987 - val_accuracy: 0.2786\n",
      "Epoch 297/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0164 - accuracy: 0.5122 - val_loss: 4.4187 - val_accuracy: 0.2786\n",
      "Epoch 298/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0245 - accuracy: 0.5013 - val_loss: 3.1498 - val_accuracy: 0.2786\n",
      "Epoch 299/400\n",
      "980/980 [==============================] - 13s 13ms/step - loss: 1.0192 - accuracy: 0.5100 - val_loss: 4.2324 - val_accuracy: 0.2786\n",
      "Epoch 300/400\n",
      "980/980 [==============================] - 12s 13ms/step - loss: 1.0251 - accuracy: 0.5034 - val_loss: 3.6830 - val_accuracy: 0.2786\n",
      "Epoch 301/400\n",
      "980/980 [==============================] - 16s 16ms/step - loss: 1.0181 - accuracy: 0.5108 - val_loss: 3.5047 - val_accuracy: 0.2786\n",
      "Epoch 302/400\n",
      "980/980 [==============================] - 12s 13ms/step - loss: 1.0198 - accuracy: 0.5066 - val_loss: 3.5960 - val_accuracy: 0.2786\n",
      "Epoch 303/400\n",
      "980/980 [==============================] - 12s 13ms/step - loss: 1.0172 - accuracy: 0.5111 - val_loss: 3.8022 - val_accuracy: 0.2786\n",
      "Epoch 304/400\n",
      "980/980 [==============================] - 13s 13ms/step - loss: 1.0198 - accuracy: 0.5074 - val_loss: 4.2974 - val_accuracy: 0.2786\n",
      "Epoch 305/400\n",
      "980/980 [==============================] - 13s 13ms/step - loss: 1.0217 - accuracy: 0.5070 - val_loss: 2.7925 - val_accuracy: 0.2786\n",
      "Epoch 306/400\n",
      "980/980 [==============================] - 13s 13ms/step - loss: 1.0216 - accuracy: 0.5085 - val_loss: 4.4635 - val_accuracy: 0.2786\n",
      "Epoch 307/400\n",
      "980/980 [==============================] - 13s 13ms/step - loss: 1.0189 - accuracy: 0.5071 - val_loss: 3.6327 - val_accuracy: 0.2786\n",
      "Epoch 308/400\n",
      "980/980 [==============================] - 13s 13ms/step - loss: 1.0224 - accuracy: 0.5022 - val_loss: 4.6789 - val_accuracy: 0.2786\n",
      "Epoch 309/400\n",
      "980/980 [==============================] - 13s 13ms/step - loss: 1.0175 - accuracy: 0.5113 - val_loss: 4.8471 - val_accuracy: 0.2786\n",
      "Epoch 310/400\n",
      "980/980 [==============================] - 12s 13ms/step - loss: 1.0180 - accuracy: 0.5088 - val_loss: 4.6934 - val_accuracy: 0.2786\n",
      "Epoch 311/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0222 - accuracy: 0.5026 - val_loss: 4.8853 - val_accuracy: 0.2786\n",
      "Epoch 312/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0206 - accuracy: 0.5059 - val_loss: 5.2877 - val_accuracy: 0.2786\n",
      "Epoch 313/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0221 - accuracy: 0.5053 - val_loss: 5.6128 - val_accuracy: 0.2786\n",
      "Epoch 314/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0260 - accuracy: 0.5012 - val_loss: 4.1270 - val_accuracy: 0.2786\n",
      "Epoch 315/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0201 - accuracy: 0.5056 - val_loss: 3.9195 - val_accuracy: 0.2786\n",
      "Epoch 316/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0263 - accuracy: 0.5017 - val_loss: 5.2344 - val_accuracy: 0.2786\n",
      "Epoch 317/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0197 - accuracy: 0.5075 - val_loss: 5.9800 - val_accuracy: 0.2786\n",
      "Epoch 318/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0260 - accuracy: 0.4981 - val_loss: 4.4089 - val_accuracy: 0.2786\n",
      "Epoch 319/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0263 - accuracy: 0.5002 - val_loss: 4.2865 - val_accuracy: 0.2786\n",
      "Epoch 320/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0175 - accuracy: 0.5104 - val_loss: 4.8714 - val_accuracy: 0.2786\n",
      "Epoch 321/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0220 - accuracy: 0.5065 - val_loss: 4.4182 - val_accuracy: 0.2786\n",
      "Epoch 322/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0231 - accuracy: 0.5040 - val_loss: 4.5236 - val_accuracy: 0.2786\n",
      "Epoch 323/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0226 - accuracy: 0.5029 - val_loss: 5.3306 - val_accuracy: 0.2786\n",
      "Epoch 324/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0262 - accuracy: 0.4982 - val_loss: 4.3006 - val_accuracy: 0.2786\n",
      "Epoch 325/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0247 - accuracy: 0.5006 - val_loss: 5.8964 - val_accuracy: 0.2786\n",
      "Epoch 326/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0262 - accuracy: 0.5009 - val_loss: 5.0198 - val_accuracy: 0.2786\n",
      "Epoch 327/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0225 - accuracy: 0.5048 - val_loss: 5.1984 - val_accuracy: 0.2786\n",
      "Epoch 328/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0216 - accuracy: 0.5031 - val_loss: 4.6001 - val_accuracy: 0.2786\n",
      "Epoch 329/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0254 - accuracy: 0.5022 - val_loss: 5.1861 - val_accuracy: 0.2786\n",
      "Epoch 330/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0253 - accuracy: 0.5026 - val_loss: 4.9504 - val_accuracy: 0.2786\n",
      "Epoch 331/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0247 - accuracy: 0.5014 - val_loss: 4.6093 - val_accuracy: 0.2786\n",
      "Epoch 332/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0176 - accuracy: 0.5056 - val_loss: 4.8693 - val_accuracy: 0.2786\n",
      "Epoch 333/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0167 - accuracy: 0.5086 - val_loss: 4.6159 - val_accuracy: 0.2786\n",
      "Epoch 334/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0167 - accuracy: 0.5077 - val_loss: 5.1108 - val_accuracy: 0.2786\n",
      "Epoch 335/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0203 - accuracy: 0.5061 - val_loss: 5.5442 - val_accuracy: 0.2786\n",
      "Epoch 336/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0266 - accuracy: 0.4991 - val_loss: 5.7375 - val_accuracy: 0.2786\n",
      "Epoch 337/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0185 - accuracy: 0.5105 - val_loss: 5.7466 - val_accuracy: 0.2786\n",
      "Epoch 338/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0250 - accuracy: 0.5006 - val_loss: 4.8822 - val_accuracy: 0.2786\n",
      "Epoch 339/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0241 - accuracy: 0.5023 - val_loss: 5.3120 - val_accuracy: 0.2786\n",
      "Epoch 340/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0224 - accuracy: 0.5054 - val_loss: 4.9717 - val_accuracy: 0.2786\n",
      "Epoch 341/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0206 - accuracy: 0.5072 - val_loss: 4.8154 - val_accuracy: 0.2786\n",
      "Epoch 342/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0230 - accuracy: 0.5073 - val_loss: 5.1339 - val_accuracy: 0.2786\n",
      "Epoch 343/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0241 - accuracy: 0.5013 - val_loss: 5.5543 - val_accuracy: 0.2786\n",
      "Epoch 344/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0183 - accuracy: 0.5083 - val_loss: 5.7044 - val_accuracy: 0.2786\n",
      "Epoch 345/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0268 - accuracy: 0.5008 - val_loss: 6.3619 - val_accuracy: 0.2786\n",
      "Epoch 346/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0234 - accuracy: 0.5033 - val_loss: 5.0048 - val_accuracy: 0.2786\n",
      "Epoch 347/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0171 - accuracy: 0.5113 - val_loss: 6.2467 - val_accuracy: 0.2786\n",
      "Epoch 348/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0244 - accuracy: 0.5036 - val_loss: 5.2718 - val_accuracy: 0.2786\n",
      "Epoch 349/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0229 - accuracy: 0.5025 - val_loss: 5.8463 - val_accuracy: 0.2786\n",
      "Epoch 350/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0207 - accuracy: 0.5072 - val_loss: 5.8069 - val_accuracy: 0.2786\n",
      "Epoch 351/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0200 - accuracy: 0.5076 - val_loss: 6.1681 - val_accuracy: 0.2786\n",
      "Epoch 352/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0210 - accuracy: 0.5052 - val_loss: 6.3946 - val_accuracy: 0.2786\n",
      "Epoch 353/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0143 - accuracy: 0.5120 - val_loss: 6.0469 - val_accuracy: 0.2786\n",
      "Epoch 354/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0225 - accuracy: 0.5042 - val_loss: 5.5063 - val_accuracy: 0.2786\n",
      "Epoch 355/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0209 - accuracy: 0.5061 - val_loss: 5.6383 - val_accuracy: 0.2786\n",
      "Epoch 356/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0253 - accuracy: 0.5042 - val_loss: 5.7805 - val_accuracy: 0.2786\n",
      "Epoch 357/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0202 - accuracy: 0.5042 - val_loss: 4.1598 - val_accuracy: 0.2786\n",
      "Epoch 358/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0267 - accuracy: 0.5015 - val_loss: 4.7729 - val_accuracy: 0.2786\n",
      "Epoch 359/400\n",
      "980/980 [==============================] - 6s 6ms/step - loss: 1.0255 - accuracy: 0.5015 - val_loss: 5.2970 - val_accuracy: 0.2786\n",
      "Epoch 360/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0231 - accuracy: 0.5055 - val_loss: 5.0162 - val_accuracy: 0.2786\n",
      "Epoch 361/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0193 - accuracy: 0.5104 - val_loss: 5.3335 - val_accuracy: 0.2786\n",
      "Epoch 362/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0221 - accuracy: 0.5053 - val_loss: 5.3340 - val_accuracy: 0.2786\n",
      "Epoch 363/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0213 - accuracy: 0.5034 - val_loss: 4.5473 - val_accuracy: 0.2786\n",
      "Epoch 364/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0245 - accuracy: 0.5031 - val_loss: 6.2250 - val_accuracy: 0.2786\n",
      "Epoch 365/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0168 - accuracy: 0.5083 - val_loss: 6.4466 - val_accuracy: 0.2786\n",
      "Epoch 366/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0173 - accuracy: 0.5107 - val_loss: 6.5350 - val_accuracy: 0.2786\n",
      "Epoch 367/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0218 - accuracy: 0.5005 - val_loss: 6.5719 - val_accuracy: 0.2786\n",
      "Epoch 368/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0207 - accuracy: 0.5059 - val_loss: 7.2567 - val_accuracy: 0.2786\n",
      "Epoch 369/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0232 - accuracy: 0.5032 - val_loss: 6.2862 - val_accuracy: 0.2786\n",
      "Epoch 370/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0279 - accuracy: 0.4984 - val_loss: 6.6057 - val_accuracy: 0.2786\n",
      "Epoch 371/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0191 - accuracy: 0.5056 - val_loss: 6.6848 - val_accuracy: 0.2786\n",
      "Epoch 372/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0265 - accuracy: 0.5001 - val_loss: 4.9186 - val_accuracy: 0.2786\n",
      "Epoch 373/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0247 - accuracy: 0.5000 - val_loss: 5.6305 - val_accuracy: 0.2786\n",
      "Epoch 374/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0178 - accuracy: 0.5082 - val_loss: 5.9995 - val_accuracy: 0.2786\n",
      "Epoch 375/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0138 - accuracy: 0.5156 - val_loss: 5.4988 - val_accuracy: 0.2786\n",
      "Epoch 376/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0229 - accuracy: 0.5014 - val_loss: 5.6979 - val_accuracy: 0.2786\n",
      "Epoch 377/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0212 - accuracy: 0.5053 - val_loss: 5.5011 - val_accuracy: 0.2786\n",
      "Epoch 378/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0205 - accuracy: 0.5065 - val_loss: 6.3612 - val_accuracy: 0.2786\n",
      "Epoch 379/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0229 - accuracy: 0.5006 - val_loss: 6.0500 - val_accuracy: 0.2786\n",
      "Epoch 380/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0217 - accuracy: 0.5037 - val_loss: 6.1867 - val_accuracy: 0.2786\n",
      "Epoch 381/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0175 - accuracy: 0.5097 - val_loss: 6.5659 - val_accuracy: 0.2786\n",
      "Epoch 382/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0228 - accuracy: 0.5057 - val_loss: 6.5265 - val_accuracy: 0.2786\n",
      "Epoch 383/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0239 - accuracy: 0.5015 - val_loss: 6.5271 - val_accuracy: 0.2786\n",
      "Epoch 384/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0259 - accuracy: 0.5001 - val_loss: 4.6221 - val_accuracy: 0.2786\n",
      "Epoch 385/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0204 - accuracy: 0.5080 - val_loss: 4.9557 - val_accuracy: 0.2786\n",
      "Epoch 386/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0198 - accuracy: 0.5105 - val_loss: 4.3985 - val_accuracy: 0.2786\n",
      "Epoch 387/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0232 - accuracy: 0.5018 - val_loss: 5.3982 - val_accuracy: 0.2786\n",
      "Epoch 388/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0199 - accuracy: 0.5104 - val_loss: 5.3783 - val_accuracy: 0.2786\n",
      "Epoch 389/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0229 - accuracy: 0.5021 - val_loss: 4.2565 - val_accuracy: 0.2786\n",
      "Epoch 390/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0241 - accuracy: 0.5017 - val_loss: 4.5622 - val_accuracy: 0.2786\n",
      "Epoch 391/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0209 - accuracy: 0.5064 - val_loss: 4.3309 - val_accuracy: 0.2786\n",
      "Epoch 392/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0240 - accuracy: 0.5013 - val_loss: 4.1689 - val_accuracy: 0.2786\n",
      "Epoch 393/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0205 - accuracy: 0.5087 - val_loss: 3.6108 - val_accuracy: 0.2786\n",
      "Epoch 394/400\n",
      "980/980 [==============================] - 13s 13ms/step - loss: 1.0212 - accuracy: 0.5043 - val_loss: 4.7883 - val_accuracy: 0.2786\n",
      "Epoch 395/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980/980 [==============================] - 13s 13ms/step - loss: 1.0271 - accuracy: 0.5008 - val_loss: 4.6153 - val_accuracy: 0.2786\n",
      "Epoch 396/400\n",
      "980/980 [==============================] - 12s 13ms/step - loss: 1.0197 - accuracy: 0.5081 - val_loss: 5.2844 - val_accuracy: 0.2786\n",
      "Epoch 397/400\n",
      "980/980 [==============================] - 12s 13ms/step - loss: 1.0255 - accuracy: 0.4980 - val_loss: 5.3033 - val_accuracy: 0.2786\n",
      "Epoch 398/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0223 - accuracy: 0.5029 - val_loss: 4.7607 - val_accuracy: 0.2786\n",
      "Epoch 399/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0190 - accuracy: 0.5084 - val_loss: 5.0616 - val_accuracy: 0.2786\n",
      "Epoch 400/400\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 1.0246 - accuracy: 0.5033 - val_loss: 4.4161 - val_accuracy: 0.2786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2531900e820>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "vgg_model.fit(train_data, train_labels,\n",
    "          batch_size=batch_size,\n",
    "          epochs=400,\n",
    "          validation_data=(valid_data, valid_labels))\n",
    "vgg_model.save_weights('model/second_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215e7211",
   "metadata": {},
   "source": [
    "### 세 번째 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "393b3303",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model2 = applications.vgg16.VGG16(include_top=False, weights='imagenet', input_shape=(150,150,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b826633e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x00000252A2F01E80> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000252A30DFAC0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000002530F5BA280> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x00000252A30DF220> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000252A305E400> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000025318E45FA0> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x00000252A2F01AC0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000002530F5BA2B0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000002530F5BA3D0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000025318E82940> True\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x000002530FAD34F0> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000253008053A0> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000252A2F240A0> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x000002530F773970> True\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x00000252A30DFCA0> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x000002530F7731F0> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000252A2F0CEE0> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000252A2F19F40> True\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x00000252A30DF0A0> True\n"
     ]
    }
   ],
   "source": [
    "for layer in vgg_model2.layers[:-10]:\n",
    "    layer.trainable = False\n",
    "for layer in vgg_model2.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c29ee95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 4, 4, 512)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(15680, 4, 4, 512)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model2.output_shape\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eb1f5041",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot assign to variable dense_48/kernel:0 due to variable shape (64, 32) and value shape (64, 3) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-e49f659b423c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtop_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mvgg_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtop_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model/second_model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[0;32m   2299\u001b[0m             f, self.layers, skip_mismatch=skip_mismatch)\n\u001b[0;32m   2300\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2301\u001b[1;33m         \u001b[0mhdf5_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2303\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers)\u001b[0m\n\u001b[0;32m    711\u001b[0m                        str(len(weight_values)) + ' elements.')\n\u001b[0;32m    712\u001b[0m     \u001b[0mweight_value_tuples\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 713\u001b[1;33m   \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   3767\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3768\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3769\u001b[1;33m       \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3770\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3771\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[0;32m    896\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m           \u001b[0mtensor_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\" \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 898\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    899\u001b[0m             (\"Cannot assign to variable%s due to variable shape %s and value \"\n\u001b[0;32m    900\u001b[0m              \"shape %s are incompatible\") %\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot assign to variable dense_48/kernel:0 due to variable shape (64, 32) and value shape (64, 3) are incompatible"
     ]
    }
   ],
   "source": [
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=vgg_model2.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.4))\n",
    "top_model.add(Dense(64, activation='relu'))\n",
    "top_model.add(Dropout(0.4))\n",
    "top_model.add(Dense(32, activation='relu'))\n",
    "top_model.add(Dropout(0.4))\n",
    "vgg_model.add(Dense(3, activation='softmax'))\n",
    "top_model.load_weights('model/second_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc5418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Sequential()\n",
    "for l in vgg_model2.layers:\n",
    "    new_model.add(l)\n",
    "for l in vgg_model2.layers:\n",
    "    new_model.add(l)\n",
    "    \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
