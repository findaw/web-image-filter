{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2fa8334",
   "metadata": {},
   "source": [
    "### 모듈 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5640e314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings             \n",
    "warnings.filterwarnings(action='ignore')          # 경고 문구 무시\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"   # 셀 하나에 ouput 모두 출력 가능\n",
    "import numpy as np                            \n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "#  한글글꼴로 변경\n",
    "plt.rcParams['font.size'] = 12.0\n",
    "# plt.rcParams['font.family'] = 'batang'\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'  \n",
    "plt.rc('axes', unicode_minus = False)\n",
    "\n",
    "# plot 크기\n",
    "plt.rc('figure', figsize=(10,6))\n",
    "\n",
    "# 음수 표시 에러 \n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "import json\n",
    "pd.options.display.max_rows= 10    # 화면에 최대 12개까지 결과 출력\n",
    "np.random.seed(0)\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43e80435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "from keras.applications import vgg16\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "408358ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def set_env():\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    config = tf.compat.v1.ConfigProto(log_device_placement=True)\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.75\n",
    "    session = tf.compat.v1.Session(config=config)\n",
    "    session\n",
    "set_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bc84d2",
   "metadata": {},
   "source": [
    "### ImgaeDataenertator\n",
    "컨볼루션 신경망 모델을 위한 데이터 부풀리기 클래스\n",
    "+ 학습 도중에 이미지에 임의 변형 및 정규화 적용\n",
    "+ 변형된 이미지를 배치 단위로 불러올 수 있는 generator 생성.\n",
    "    + generator를 생성할 때 flow(data, labels), flow_from_directory(directory) 두 가지 함수를 사용합니다.\n",
    "    + fit_generator, evaluate_generator 함수를 이용하여 generator로 이미지를 불러와서 모델을 학습시킬 수 있습니\n",
    "\n",
    "#### 파라미터(기본값)\n",
    "<code style=\"display:block\">\n",
    "+keras.preprocessing.image.ImageDataGenerator(\n",
    "featurewise_center=False,\n",
    "samplewise_center=False,\n",
    "featurewise_std_normalization=False,\n",
    "samplewise_std_normalization=False,\n",
    "zca_whitening=False,\n",
    "rotation_range=0.,\n",
    "width_shift_range=0.,\n",
    "height_shift_range=0.,\n",
    "shear_range=0.,\n",
    "zoom_range=0.,\n",
    "channel_shift_range=0.,\n",
    "fill_mode='nearest',\n",
    "cval=0.,\n",
    "horizontal_flip=False,\n",
    "vertical_flip=False,\n",
    "rescale=None,\n",
    "preprocessing_function=None,\n",
    "data_format=K.image_data_format())\n",
    "</code>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff200522",
   "metadata": {},
   "source": [
    "+ shear_range : 범위 내에서 임의로 원본 이미지 변형(0.5면 0~0.5각도로 )\n",
    "+ zoom_range : 지정된 범위내로 임의로 원본이미지 확대/축소 0.3 이면 -0.3~0.3 범위 로 확대축소\n",
    "+ rotation_range : 지정된 각도 범위내로 임의로 원본 이미지 회전(90이면 0~90 다함)\n",
    "+ width_shift_range : 지정된 수평방향 이동 범위로 원본 이미지 이동 : 0.1이면 넓이 100에서 0~10px 좌우 이동\n",
    "+ height_shift_range :수직방향\n",
    "+ vertical_flip : 수직방향 뒤집기 (boolean)\n",
    "+ horizontal_flip 수평방향 뒤집기 True일경우 50% 확률로 이미지를 수평으로 뒤집\n",
    "+ fill_mode 이미지를 회전, 이동하거나 축소할 때 생기는 공간을 채우는 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae1497a",
   "metadata": {},
   "source": [
    "데이터 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e286207",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.getcwd() + '\\\\dataset\\\\train'\n",
    "test_path = os.getcwd() + '\\\\dataset\\\\test'\n",
    "valid_path = os.getcwd() + '\\\\dataset\\\\val'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c461b1a",
   "metadata": {},
   "source": [
    "### 이미지 유효성 검사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c78960c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_train_data(): \n",
    "    data_input = []\n",
    "    error_paths = []\n",
    "    for path in [train_path, test_path, valid_path]:\n",
    "        label_dirs = os.listdir(path)\n",
    "        for dir_name in label_dirs:\n",
    "            file_list = os.listdir(f'{path}\\\\{dir_name}')\n",
    "            for file_name in file_list:\n",
    "                try:\n",
    "#                     print(file_name)\n",
    "                    img = Image.open(f'{path}\\\\{dir_name}\\\\{file_name}')\n",
    "                    im = img.load()\n",
    "\n",
    "                except Exception as e:\n",
    "                        err_string = f'[Error!] at {path}\\\\{dir_name}\\\\{file_name}'\n",
    "                        error_paths.append(err_string)\n",
    "                        print(err_string)\n",
    "                        print(e)\n",
    "                        continue\n",
    "\n",
    "\n",
    "get_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25eb56fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6ce5b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f4ac61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c51e276c",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8fd39b",
   "metadata": {},
   "source": [
    "검증 및 테스트 이미지는 augmentation을 적용하지 않습니다. 모델 성능을 평가할 때에는 이미지 원본을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cf65db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataGen = ImageDataGenerator(\n",
    "                       rescale=1/255,              # scale\n",
    "                       fill_mode='nearest',        # 변형시 공간 채우는방식\n",
    "                       rotation_range=40,         # 회전\n",
    "                       shear_range=.2,           # 전단 변환\n",
    "                       vertical_flip=True,      # 수직 뒤집기\n",
    "                       horizontal_flip=True,    # 수평 뒤집기\n",
    "                       height_shift_range=.2,    # 이미지 수직 이동\n",
    "                       width_shift_range=.2,    # 수평 이동\n",
    "                       zoom_range=.2,          # -0.2~0.2 확대 축소\n",
    ")\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d1c12c",
   "metadata": {},
   "source": [
    "#### 데이터 디버깅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fd05cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "                       fill_mode='nearest',        # 변형시 공간 채우는방식\n",
    "                       rotation_range=40,         # 회전\n",
    "                       shear_range=.2,           # 전단 변환\n",
    "                       vertical_flip=True,      # 수직 뒤집기\n",
    "                       horizontal_flip=True,    # 수평 뒤집기\n",
    "                       height_shift_range=.2,    # 이미지 수직 이동\n",
    "                       width_shift_range=.2,    # 수평 이동\n",
    "                       zoom_range=.2,          # -0.2~0.2 확대 축소\n",
    ")         \n",
    "\n",
    "img = load_img('C:/project/phobiaFilter/dataset/train/cockroach_many/cockr534.jpg')  # PIL 이미지\n",
    "img2 = load_img('C:/project/phobiaFilter/dataset/train/cockroach_many/cockroache-1569.jpg')  # PIL 이미지\n",
    "\n",
    "x = img_to_array(img)  # (3, 150, 150) 크기의 NumPy 배열\n",
    "x = x.reshape((1,) + x.shape)  \n",
    "x2 = img_to_array(img2)  # (3, 150, 150) 크기의 NumPy 배열\n",
    "x2 = x2.reshape((1,) + x2.shape)  \n",
    "\n",
    "# 아래 .flow() 함수는 임의 변환된 이미지를 배치 단위로 생성해서\n",
    "# 지정된 `preview/` 폴더에 저장합니다.\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir='C:\\project\\phobiaFilter\\dataset\\preview', save_prefix='cocks', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 40:\n",
    "        break  # 이미지 20장을 생성하고 마칩니다\n",
    "\n",
    "i=0\n",
    "for batch in datagen.flow(x2, batch_size=1,\n",
    "                  save_to_dir='C:\\project\\phobiaFilter\\dataset\\preview', save_prefix='cocks2', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 40:\n",
    "        break  # 이미지 20장을 생성하고 마칩니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91610254",
   "metadata": {},
   "source": [
    "#### Data 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8902381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20384 images belonging to 11 classes.\n",
      "Found 8203 images belonging to 11 classes.\n",
      "Found 4231 images belonging to 11 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x1ebad901370>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x1ebc08eabe0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x1ebb51cbdf0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "train_generator = train_dataGen.flow_from_directory(train_path, target_size=(150,150), batch_size=batch_size, class_mode='categorical')\n",
    "test_generator = valid_datagen.flow_from_directory(test_path, target_size=(150,150), batch_size=batch_size, class_mode='categorical')\n",
    "valid_generator = test_datagen.flow_from_directory(valid_path, target_size=(150,150), batch_size=batch_size, class_mode='categorical')\n",
    "train_generator\n",
    "test_generator\n",
    "valid_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "844116b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chocoball': 0,\n",
       " 'cockroach_egg': 1,\n",
       " 'cockroach_etc': 2,\n",
       " 'cockroach_face': 3,\n",
       " 'cockroach_fly': 4,\n",
       " 'cockroach_many': 5,\n",
       " 'cockroach_noraml': 6,\n",
       " 'cockroach_pic': 7,\n",
       " 'etc': 8,\n",
       " 'spider': 9,\n",
       " 'tick': 10}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices\n",
    "len(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fc6b40",
   "metadata": {},
   "source": [
    "엔트로피 용량을 조절하는 방법은 다양합니다. 대표적으로 모델에 관여하는 파라미터 개수를 조절하는 방법이 있습니다. 레이어 개수와 레이어 크기가 여기에 해당하죠. 저희가 작은 규모의 CNN을 사용하는 이유가 여기에 있습니다. 또한, L1, L2 정규화 (regularization) 같은 가중치 정규화 기법이 있습니다. 학습하면서 모든 가중치를 반복적으로 축소하는 방법인데, 결과적으로 핵심적인 특징에 대한 가중치만 남게 되는 효과가 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de9e028",
   "metadata": {},
   "source": [
    "### 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fecf35b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model = keras.Sequential()\n",
    "# # 필터 층 추가 \n",
    "# # same 패딩을 적용했기 때문에 특성맵과 입력의 크기가 동일\n",
    "# model.add(keras.layers.Conv2D(32, kernel_size=10, activation='relu',\n",
    "#                               padding='same', input_shape=(150,150,1)))\n",
    "\n",
    "# model.add(keras.layers.MaxPooling2D(2))\n",
    "# model.add(keras.layers.Conv2D(64, kernel_size=10, activation='relu', padding='same'))\n",
    "# model.add(keras.layers.MaxPooling2D(2))\n",
    "# model.add(keras.layers.Flatten())    # 출력층 입력을 위해 1차원 변환\n",
    "# model.add(keras.layers.Dense(200, activation='relu'))\n",
    "# model.add(keras.layers.Dropout(0.4))            # 과대적합 방지 \n",
    "# model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "# model.summary()\n",
    "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "# checkpoint_cb = keras.callbacks.ModelCheckpoint('model/best-cnn-model.h5')\n",
    "# early_stopping_cb = keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)\n",
    "# history = model.fit(train_scaled, train_target, epochs=20, validation_data=(valid_scaled, valid_target),\n",
    "#                     callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.xlabel('epoch')\n",
    "# plt.ylabel('loss')\n",
    "# plt.legend(['train', 'val'])\n",
    "# plt.show();\n",
    "\n",
    "\n",
    "# model.evaluate(valid_scaled, valid_target)\n",
    "# model.evaluate(test_scaled, test_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b3d41d",
   "metadata": {},
   "source": [
    "### 정확도와 손실율 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2eafdbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# acc = history.history['accuracy']\n",
    "# val_acc = history.history['val_accuracy']\n",
    "# loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "\n",
    "# epochs = range(len(acc))\n",
    "\n",
    "# plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "# plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "# plt.title('Training and validation accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.figure()\n",
    "\n",
    "# plt.plot(epochs, loss, 'go', label='Training Loss')\n",
    "# plt.plot(epochs, val_loss, 'g', label='Validation Loss')\n",
    "# plt.title('Training and validation loss')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd394528",
   "metadata": {},
   "source": [
    "### 첫 번째 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "772464ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1274/1274 [==============================] - 238s 175ms/step - loss: 1.6737 - accuracy: 0.3627 - val_loss: 1.7809 - val_accuracy: 0.4628\n",
      "Epoch 2/50\n",
      "1274/1274 [==============================] - 223s 175ms/step - loss: 1.5553 - accuracy: 0.3937 - val_loss: 1.7552 - val_accuracy: 0.4628\n",
      "Epoch 3/50\n",
      "1274/1274 [==============================] - 230s 180ms/step - loss: 1.5641 - accuracy: 0.3887 - val_loss: 1.7453 - val_accuracy: 0.4628\n",
      "Epoch 4/50\n",
      "1274/1274 [==============================] - 231s 181ms/step - loss: 1.5395 - accuracy: 0.3895 - val_loss: 1.7473 - val_accuracy: 0.4628\n",
      "Epoch 5/50\n",
      "1183/1274 [==========================>...] - ETA: 13s - loss: 1.5315 - accuracy: 0.3926"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-83603832b21a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m               metrics='accuracy')\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m model.fit_generator(\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1916\u001b[0m                   \u001b[1;34m'will be removed in a future version. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1917\u001b[0m                   'Please use `Model.fit`, which supports generators.')\n\u001b[1;32m-> 1918\u001b[1;33m     return self.fit(\n\u001b[0m\u001b[0;32m   1919\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1156\u001b[0m                 _r=1):\n\u001b[0;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1158\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1159\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(32, activation='relu', kernel_size=10, padding='same', input_shape=(150,150,3)))\n",
    "model.add(MaxPooling2D(2))\n",
    "\n",
    "model.add(Conv2D(32, activation='relu', kernel_size=10, padding='same', input_shape=(150,150,3)))\n",
    "model.add(MaxPooling2D(2))\n",
    "\n",
    "model.add(Conv2D(64, activation='relu', kernel_size=10, padding='same', input_shape=(150,150,3)))\n",
    "model.add(MaxPooling2D(2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(11, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics='accuracy')\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        validation_data=valid_generator,\n",
    "#         steps_per_epoch=1000//batchsize,\n",
    "#         validation_steps=50,\n",
    "    #verbose=2\n",
    "        epochs=50)\n",
    "model.save_weights('model/first_model.h5')  # 많은 시간을 들여 학습한 모델인 만큼, 학습 후에는 꼭 모델을 저장해줍시다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a37d387c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "62/62 [==============================] - 44s 702ms/step - loss: 1.8849 - accuracy: 0.3134 - val_loss: 1.8089 - val_accuracy: 0.3101\n",
      "Epoch 2/50\n",
      "62/62 [==============================] - 44s 716ms/step - loss: 1.6883 - accuracy: 0.3658 - val_loss: 1.7769 - val_accuracy: 0.1078\n",
      "Epoch 3/50\n",
      "62/62 [==============================] - 43s 703ms/step - loss: 1.5756 - accuracy: 0.3602 - val_loss: 1.8426 - val_accuracy: 0.4486\n",
      "Epoch 4/50\n",
      "62/62 [==============================] - 42s 685ms/step - loss: 1.6400 - accuracy: 0.3293 - val_loss: 1.7398 - val_accuracy: 0.4628\n",
      "Epoch 5/50\n",
      "62/62 [==============================] - 43s 698ms/step - loss: 1.6246 - accuracy: 0.3591 - val_loss: 1.8209 - val_accuracy: 0.4628\n",
      "Epoch 6/50\n",
      "62/62 [==============================] - 42s 692ms/step - loss: 1.5442 - accuracy: 0.3720 - val_loss: 1.6792 - val_accuracy: 0.4628\n",
      "Epoch 7/50\n",
      "62/62 [==============================] - 43s 703ms/step - loss: 1.4977 - accuracy: 0.4126 - val_loss: 1.7244 - val_accuracy: 0.4108\n",
      "Epoch 8/50\n",
      "62/62 [==============================] - 51s 833ms/step - loss: 1.5428 - accuracy: 0.3896 - val_loss: 1.6846 - val_accuracy: 0.4632\n",
      "Epoch 9/50\n",
      "62/62 [==============================] - 43s 702ms/step - loss: 1.4866 - accuracy: 0.4248 - val_loss: 1.6751 - val_accuracy: 0.4455\n",
      "Epoch 10/50\n",
      "62/62 [==============================] - 42s 685ms/step - loss: 1.5642 - accuracy: 0.4014 - val_loss: 1.6690 - val_accuracy: 0.4599\n",
      "Epoch 11/50\n",
      "62/62 [==============================] - 43s 705ms/step - loss: 1.5628 - accuracy: 0.3878 - val_loss: 1.6488 - val_accuracy: 0.4554\n",
      "Epoch 12/50\n",
      "62/62 [==============================] - 42s 689ms/step - loss: 1.5092 - accuracy: 0.3705 - val_loss: 1.6448 - val_accuracy: 0.4585\n",
      "Epoch 13/50\n",
      "62/62 [==============================] - 41s 677ms/step - loss: 1.5666 - accuracy: 0.3702 - val_loss: 1.6586 - val_accuracy: 0.4420\n",
      "Epoch 14/50\n",
      "62/62 [==============================] - 42s 689ms/step - loss: 1.4657 - accuracy: 0.3890 - val_loss: 1.6883 - val_accuracy: 0.4628\n",
      "Epoch 15/50\n",
      "62/62 [==============================] - 44s 713ms/step - loss: 1.5664 - accuracy: 0.3906 - val_loss: 1.7000 - val_accuracy: 0.2349\n",
      "Epoch 16/50\n",
      "62/62 [==============================] - 42s 690ms/step - loss: 1.5687 - accuracy: 0.3240 - val_loss: 1.6676 - val_accuracy: 0.4628\n",
      "Epoch 17/50\n",
      "62/62 [==============================] - 43s 706ms/step - loss: 1.5826 - accuracy: 0.3738 - val_loss: 1.6729 - val_accuracy: 0.4505\n",
      "Epoch 18/50\n",
      "62/62 [==============================] - 42s 694ms/step - loss: 1.4640 - accuracy: 0.3918 - val_loss: 1.6271 - val_accuracy: 0.4621\n",
      "Epoch 19/50\n",
      "62/62 [==============================] - 43s 699ms/step - loss: 1.5108 - accuracy: 0.3831 - val_loss: 1.6632 - val_accuracy: 0.3595\n",
      "Epoch 20/50\n",
      "54/62 [=========================>....] - ETA: 1s - loss: 1.5295 - accuracy: 0.4079"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "2 root error(s) found.\n  (0) Unknown:  UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x000002CC640F9900>\nTraceback (most recent call last):\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 645, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 961, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 821, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 947, in generator_fn\n    yield x[i]\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 227, in _get_batches_of_transformed_samples\n    img = load_img(filepaths[j],\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\", line 114, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\", line 2967, in open\n    raise UnidentifiedImageError(\n\nPIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x000002CC640F9900>\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_7]]\n  (1) Unknown:  UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x000002CC640F9900>\nTraceback (most recent call last):\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 645, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 961, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 821, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 947, in generator_fn\n    yield x[i]\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 227, in _get_batches_of_transformed_samples\n    img = load_img(filepaths[j],\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\", line 114, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\", line 2967, in open\n    raise UnidentifiedImageError(\n\nPIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x000002CC640F9900>\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_19333]\n\nFunction call stack:\ntrain_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-818c1fe5506c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m---> 24\u001b[1;33m model.fit_generator(\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1916\u001b[0m                   \u001b[1;34m'will be removed in a future version. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1917\u001b[0m                   'Please use `Model.fit`, which supports generators.')\n\u001b[1;32m-> 1918\u001b[1;33m     return self.fit(\n\u001b[0m\u001b[0;32m   1919\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1156\u001b[0m                 _r=1):\n\u001b[0;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1158\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1159\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown:  UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x000002CC640F9900>\nTraceback (most recent call last):\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 645, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 961, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 821, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 947, in generator_fn\n    yield x[i]\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 227, in _get_batches_of_transformed_samples\n    img = load_img(filepaths[j],\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\", line 114, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\", line 2967, in open\n    raise UnidentifiedImageError(\n\nPIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x000002CC640F9900>\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_7]]\n  (1) Unknown:  UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x000002CC640F9900>\nTraceback (most recent call last):\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 645, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 961, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 821, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 947, in generator_fn\n    yield x[i]\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 227, in _get_batches_of_transformed_samples\n    img = load_img(filepaths[j],\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\", line 114, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\", line 2967, in open\n    raise UnidentifiedImageError(\n\nPIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x000002CC640F9900>\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_19333]\n\nFunction call stack:\ntrain_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150,150,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # 이전 CNN 레이어에서 나온 3차원 배열은 1차원으로 뽑아줍니다\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_generator.class_indices)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=1000 // batch_size,\n",
    "        validation_data=valid_generator,\n",
    "        epochs=50)\n",
    "model.save_weights('model/first_model.h5')  # 많은 시간을 들여 학습한 모델인 만큼, 학습 후에는 꼭 모델을 저장해줍시다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff1220b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa00e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d572218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
